{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/config/generateJobsJSONSchemas.ts"],"sourcesContent":["import type { I18n } from '@payloadcms/translations'\nimport type { JSONSchema4 } from 'json-schema'\n\nimport type { SanitizedConfig } from '../../config/types.js'\nimport type { JobsConfig } from './types/index.js'\n\nimport { fieldsToJSONSchema } from '../../utilities/configToJSONSchema.js'\nimport { flattenAllFields } from '../../utilities/flattenAllFields.js'\nexport function generateJobsJSONSchemas(\n  config: SanitizedConfig,\n  jobsConfig: JobsConfig,\n  interfaceNameDefinitions: Map<string, JSONSchema4>,\n  /**\n   * Used for relationship fields, to determine whether to use a string or number type for the ID.\n   * While there is a default ID field type set by the db adapter, they can differ on a collection-level\n   * if they have custom ID fields.\n   */\n  collectionIDFieldTypes: { [key: string]: 'number' | 'string' },\n  i18n?: I18n,\n): {\n  definitions?: Map<string, JSONSchema4>\n  properties?: { tasks: JSONSchema4 }\n} {\n  const properties: { tasks: JSONSchema4; workflows: JSONSchema4 } = {\n    tasks: {},\n    workflows: {},\n  }\n  const definitions: Map<string, JSONSchema4> = new Map()\n\n  if (jobsConfig?.tasks?.length) {\n    for (const task of jobsConfig.tasks) {\n      const fullTaskJsonSchema: JSONSchema4 = {\n        type: 'object',\n        additionalProperties: false,\n        properties: {\n          input: {},\n          output: {},\n        },\n        required: [],\n      }\n      if (task?.inputSchema?.length) {\n        const inputJsonSchema = fieldsToJSONSchema(\n          collectionIDFieldTypes,\n          flattenAllFields({ fields: task.inputSchema }),\n          interfaceNameDefinitions,\n          config,\n          i18n,\n        )\n\n        const fullInputJsonSchema: JSONSchema4 = {\n          type: 'object',\n          additionalProperties: false,\n          properties: inputJsonSchema.properties,\n          required: inputJsonSchema.required,\n        }\n\n        fullTaskJsonSchema.properties!.input = fullInputJsonSchema\n        ;(fullTaskJsonSchema.required as string[]).push('input')\n      }\n      if (task?.outputSchema?.length) {\n        const outputJsonSchema = fieldsToJSONSchema(\n          collectionIDFieldTypes,\n          flattenAllFields({ fields: task.outputSchema }),\n          interfaceNameDefinitions,\n          config,\n          i18n,\n        )\n\n        const fullOutputJsonSchema: JSONSchema4 = {\n          type: 'object',\n          additionalProperties: false,\n          properties: outputJsonSchema.properties,\n          required: outputJsonSchema.required,\n        }\n\n        fullTaskJsonSchema.properties!.output = fullOutputJsonSchema\n        ;(fullTaskJsonSchema.required as string[]).push('output')\n      }\n\n      const normalizedTaskSlug = task.slug[0].toUpperCase() + task.slug.slice(1)\n\n      definitions.set(task.interfaceName ?? `Task${normalizedTaskSlug}`, fullTaskJsonSchema)\n    }\n    // Now add properties.tasks definition that references the types in definitions keyed by task slug:\n    properties.tasks = {\n      type: 'object',\n      additionalProperties: false,\n      properties: {\n        ...Object.fromEntries(\n          (jobsConfig.tasks ?? []).map((task) => {\n            const normalizedTaskSlug = task.slug[0].toUpperCase() + task.slug.slice(1)\n\n            const toReturn: JSONSchema4 = {\n              $ref: task.interfaceName\n                ? `#/definitions/${task.interfaceName}`\n                : `#/definitions/Task${normalizedTaskSlug}`,\n            }\n\n            return [task.slug, toReturn]\n          }),\n        ),\n        inline: {\n          type: 'object',\n          additionalProperties: false,\n          properties: {\n            input: {},\n            output: {},\n          },\n          required: ['input', 'output'],\n        },\n      },\n      required: [...(jobsConfig.tasks ?? []).map((task) => task.slug), 'inline'],\n    }\n  }\n\n  if (jobsConfig?.workflows?.length) {\n    for (const workflow of jobsConfig.workflows) {\n      const fullWorkflowJsonSchema: JSONSchema4 = {\n        type: 'object',\n        additionalProperties: false,\n        properties: {\n          input: {},\n        },\n        required: [],\n      }\n\n      if (workflow?.inputSchema?.length) {\n        const inputJsonSchema = fieldsToJSONSchema(\n          collectionIDFieldTypes,\n          flattenAllFields({ fields: workflow.inputSchema }),\n          interfaceNameDefinitions,\n          config,\n          i18n,\n        )\n\n        const fullInputJsonSchema: JSONSchema4 = {\n          type: 'object',\n          additionalProperties: false,\n          properties: inputJsonSchema.properties,\n          required: inputJsonSchema.required,\n        }\n\n        fullWorkflowJsonSchema.properties!.input = fullInputJsonSchema\n        ;(fullWorkflowJsonSchema.required as string[]).push('input')\n      }\n      const normalizedWorkflowSlug = workflow.slug[0].toUpperCase() + workflow.slug.slice(1)\n\n      definitions.set(\n        workflow.interfaceName ?? `Workflow${normalizedWorkflowSlug}`,\n        fullWorkflowJsonSchema,\n      )\n\n      properties.workflows = {\n        type: 'object',\n        additionalProperties: false,\n        properties: Object.fromEntries(\n          jobsConfig.workflows.map((workflow) => {\n            const normalizedWorkflowSlug = workflow.slug[0].toUpperCase() + workflow.slug.slice(1)\n\n            const toReturn: JSONSchema4 = {\n              $ref: workflow.interfaceName\n                ? `#/definitions/${workflow.interfaceName}`\n                : `#/definitions/Workflow${normalizedWorkflowSlug}`,\n            }\n\n            return [workflow.slug, toReturn]\n          }),\n        ),\n        required: jobsConfig.workflows.map((workflow) => workflow.slug),\n      }\n    }\n  }\n\n  return {\n    definitions,\n    properties,\n  }\n}\n"],"names":["fieldsToJSONSchema","flattenAllFields","generateJobsJSONSchemas","config","jobsConfig","interfaceNameDefinitions","collectionIDFieldTypes","i18n","properties","tasks","workflows","definitions","Map","length","task","fullTaskJsonSchema","type","additionalProperties","input","output","required","inputSchema","inputJsonSchema","fields","fullInputJsonSchema","push","outputSchema","outputJsonSchema","fullOutputJsonSchema","normalizedTaskSlug","slug","toUpperCase","slice","set","interfaceName","Object","fromEntries","map","toReturn","$ref","inline","workflow","fullWorkflowJsonSchema","normalizedWorkflowSlug"],"mappings":";;;;AAMA,SAASA,kBAAkB,QAAQ,wCAAuC;AAC1E,SAASC,gBAAgB,QAAQ,sCAAqC;;;AAC/D,SAASC,wBACdC,MAAuB,EACvBC,UAAsB,EACtBC,wBAAkD,EAClD;;;;GAIC,GACDC,sBAA8D,EAC9DC,IAAW;IAKX,MAAMC,aAA6D;QACjEC,OAAO,CAAC;QACRC,WAAW,CAAC;IACd;IACA,MAAMC,cAAwC,IAAIC;IAElD,IAAIR,YAAYK,OAAOI,QAAQ;QAC7B,KAAK,MAAMC,QAAQV,WAAWK,KAAK,CAAE;YACnC,MAAMM,qBAAkC;gBACtCC,MAAM;gBACNC,sBAAsB;gBACtBT,YAAY;oBACVU,OAAO,CAAC;oBACRC,QAAQ,CAAC;gBACX;gBACAC,UAAU,EAAE;YACd;YACA,IAAIN,MAAMO,aAAaR,QAAQ;gBAC7B,MAAMS,sBAAkBtB,kSAAAA,EACtBM,4BACAL,8RAAAA,EAAiB;oBAAEsB,QAAQT,KAAKO,WAAW;gBAAC,IAC5ChB,0BACAF,QACAI;gBAGF,MAAMiB,sBAAmC;oBACvCR,MAAM;oBACNC,sBAAsB;oBACtBT,YAAYc,gBAAgBd,UAAU;oBACtCY,UAAUE,gBAAgBF,QAAQ;gBACpC;gBAEAL,mBAAmBP,UAAU,CAAEU,KAAK,GAAGM;gBACrCT,mBAAmBK,QAAQ,CAAcK,IAAI,CAAC;YAClD;YACA,IAAIX,MAAMY,cAAcb,QAAQ;gBAC9B,MAAMc,uBAAmB3B,kSAAAA,EACvBM,4BACAL,8RAAAA,EAAiB;oBAAEsB,QAAQT,KAAKY,YAAY;gBAAC,IAC7CrB,0BACAF,QACAI;gBAGF,MAAMqB,uBAAoC;oBACxCZ,MAAM;oBACNC,sBAAsB;oBACtBT,YAAYmB,iBAAiBnB,UAAU;oBACvCY,UAAUO,iBAAiBP,QAAQ;gBACrC;gBAEAL,mBAAmBP,UAAU,CAAEW,MAAM,GAAGS;gBACtCb,mBAAmBK,QAAQ,CAAcK,IAAI,CAAC;YAClD;YAEA,MAAMI,qBAAqBf,KAAKgB,IAAI,CAAC,EAAE,CAACC,WAAW,KAAKjB,KAAKgB,IAAI,CAACE,KAAK,CAAC;YAExErB,YAAYsB,GAAG,CAACnB,KAAKoB,aAAa,IAAI,CAAC,IAAI,EAAEL,oBAAoB,EAAEd;QACrE;QACA,mGAAmG;QACnGP,WAAWC,KAAK,GAAG;YACjBO,MAAM;YACNC,sBAAsB;YACtBT,YAAY;gBACV,GAAG2B,OAAOC,WAAW,CAClBhC,CAAAA,WAAWK,KAAK,IAAI,EAAC,EAAG4B,GAAG,CAAC,CAACvB;oBAC5B,MAAMe,qBAAqBf,KAAKgB,IAAI,CAAC,EAAE,CAACC,WAAW,KAAKjB,KAAKgB,IAAI,CAACE,KAAK,CAAC;oBAExE,MAAMM,WAAwB;wBAC5BC,MAAMzB,KAAKoB,aAAa,GACpB,CAAC,cAAc,EAAEpB,KAAKoB,aAAa,EAAE,GACrC,CAAC,kBAAkB,EAAEL,oBAAoB;oBAC/C;oBAEA,OAAO;wBAACf,KAAKgB,IAAI;wBAAEQ;qBAAS;gBAC9B,GACD;gBACDE,QAAQ;oBACNxB,MAAM;oBACNC,sBAAsB;oBACtBT,YAAY;wBACVU,OAAO,CAAC;wBACRC,QAAQ,CAAC;oBACX;oBACAC,UAAU;wBAAC;wBAAS;qBAAS;gBAC/B;YACF;YACAA,UAAU;mBAAKhB,CAAAA,WAAWK,KAAK,IAAI,EAAC,EAAG4B,GAAG,CAAC,CAACvB,OAASA,KAAKgB,IAAI;gBAAG;aAAS;QAC5E;IACF;IAEA,IAAI1B,YAAYM,WAAWG,QAAQ;QACjC,KAAK,MAAM4B,YAAYrC,WAAWM,SAAS,CAAE;YAC3C,MAAMgC,yBAAsC;gBAC1C1B,MAAM;gBACNC,sBAAsB;gBACtBT,YAAY;oBACVU,OAAO,CAAC;gBACV;gBACAE,UAAU,EAAE;YACd;YAEA,IAAIqB,UAAUpB,aAAaR,QAAQ;gBACjC,MAAMS,sBAAkBtB,kSAAAA,EACtBM,4BACAL,8RAAAA,EAAiB;oBAAEsB,QAAQkB,SAASpB,WAAW;gBAAC,IAChDhB,0BACAF,QACAI;gBAGF,MAAMiB,sBAAmC;oBACvCR,MAAM;oBACNC,sBAAsB;oBACtBT,YAAYc,gBAAgBd,UAAU;oBACtCY,UAAUE,gBAAgBF,QAAQ;gBACpC;gBAEAsB,uBAAuBlC,UAAU,CAAEU,KAAK,GAAGM;gBACzCkB,uBAAuBtB,QAAQ,CAAcK,IAAI,CAAC;YACtD;YACA,MAAMkB,yBAAyBF,SAASX,IAAI,CAAC,EAAE,CAACC,WAAW,KAAKU,SAASX,IAAI,CAACE,KAAK,CAAC;YAEpFrB,YAAYsB,GAAG,CACbQ,SAASP,aAAa,IAAI,CAAC,QAAQ,EAAES,wBAAwB,EAC7DD;YAGFlC,WAAWE,SAAS,GAAG;gBACrBM,MAAM;gBACNC,sBAAsB;gBACtBT,YAAY2B,OAAOC,WAAW,CAC5BhC,WAAWM,SAAS,CAAC2B,GAAG,CAAC,CAACI;oBACxB,MAAME,yBAAyBF,SAASX,IAAI,CAAC,EAAE,CAACC,WAAW,KAAKU,SAASX,IAAI,CAACE,KAAK,CAAC;oBAEpF,MAAMM,WAAwB;wBAC5BC,MAAME,SAASP,aAAa,GACxB,CAAC,cAAc,EAAEO,SAASP,aAAa,EAAE,GACzC,CAAC,sBAAsB,EAAES,wBAAwB;oBACvD;oBAEA,OAAO;wBAACF,SAASX,IAAI;wBAAEQ;qBAAS;gBAClC;gBAEFlB,UAAUhB,WAAWM,SAAS,CAAC2B,GAAG,CAAC,CAACI,WAAaA,SAASX,IAAI;YAChE;QACF;IACF;IAEA,OAAO;QACLnB;QACAH;IACF;AACF"}},
    {"offset": {"line": 147, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/config/global.ts"],"sourcesContent":["import type { Config } from '../../config/types.js'\nimport type { GlobalConfig } from '../../globals/config/types.js'\nimport type { TaskType } from './types/taskTypes.js'\nimport type { WorkflowTypes } from './types/workflowTypes.js'\n\nexport const jobStatsGlobalSlug = 'payload-jobs-stats'\n\n/**\n * Type for data stored in the payload-jobs-stats global.\n */\nexport type JobStats = {\n  stats?: {\n    scheduledRuns?: {\n      queues?: {\n        [queueSlug: string]: {\n          tasks?: {\n            [taskSlug: TaskType]: {\n              lastScheduledRun: string\n            }\n          }\n          workflows?: {\n            [workflowSlug: WorkflowTypes]: {\n              lastScheduledRun: string\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n/**\n * Global config for job statistics.\n */\nexport const getJobStatsGlobal: (config: Config) => GlobalConfig = (config) => {\n  return {\n    slug: jobStatsGlobalSlug,\n    admin: {\n      group: 'System',\n      hidden: true,\n    },\n    fields: [\n      {\n        name: 'stats',\n        type: 'json',\n      },\n    ],\n  }\n}\n"],"names":["jobStatsGlobalSlug","getJobStatsGlobal","config","slug","admin","group","hidden","fields","name","type"],"mappings":";;;;;;AAKO,MAAMA,qBAAqB,qBAAoB;AA6B/C,MAAMC,oBAAsD,CAACC;IAClE,OAAO;QACLC,MAAMH;QACNI,OAAO;YACLC,OAAO;YACPC,QAAQ;QACV;QACAC,QAAQ;YACN;gBACEC,MAAM;gBACNC,MAAM;YACR;SACD;IACH;AACF,EAAC"}},
    {"offset": {"line": 173, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/utilities/getCurrentDate.ts"],"sourcesContent":["/**\n * Globals that are used by our integration tests to modify the behavior of the job system during runtime.\n * This is useful to avoid having to wait for the cron jobs to run, or to pause auto-running jobs.\n */\nexport const _internal_jobSystemGlobals = {\n  getCurrentDate: () => {\n    return new Date()\n  },\n  shouldAutoRun: true,\n  shouldAutoSchedule: true,\n}\n\nexport function _internal_resetJobSystemGlobals() {\n  _internal_jobSystemGlobals.getCurrentDate = () => new Date()\n  _internal_jobSystemGlobals.shouldAutoRun = true\n  _internal_jobSystemGlobals.shouldAutoSchedule = true\n}\n\nexport const getCurrentDate: () => Date = () => {\n  return _internal_jobSystemGlobals.getCurrentDate()\n}\n"],"names":["_internal_jobSystemGlobals","getCurrentDate","Date","shouldAutoRun","shouldAutoSchedule","_internal_resetJobSystemGlobals"],"mappings":"AAAA;;;CAGC,GACD;;;;;;;;AAAO,MAAMA,6BAA6B;IACxCC,gBAAgB;QACd,OAAO,IAAIC;IACb;IACAC,eAAe;IACfC,oBAAoB;AACtB,EAAC;AAEM,SAASC;IACdL,2BAA2BC,cAAc,GAAG,IAAM,IAAIC;IACtDF,2BAA2BG,aAAa,GAAG;IAC3CH,2BAA2BI,kBAAkB,GAAG;AAClD;AAEO,MAAMH,iBAA6B;IACxC,OAAOD,2BAA2BC,cAAc;AAClD,EAAC"}},
    {"offset": {"line": 203, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/handleSchedules/defaultAfterSchedule.ts"],"sourcesContent":["import type { AfterScheduleFn } from '../../config/types/index.js'\n\nimport { type JobStats, jobStatsGlobalSlug } from '../../config/global.js'\nimport { getCurrentDate } from '../../utilities/getCurrentDate.js'\n\ntype JobStatsScheduledRuns = NonNullable<\n  NonNullable<NonNullable<JobStats['stats']>['scheduledRuns']>['queues']\n>[string]\n\nexport const defaultAfterSchedule: AfterScheduleFn = async ({ jobStats, queueable, req }) => {\n  const existingQueuesConfig =\n    jobStats?.stats?.scheduledRuns?.queues?.[queueable.scheduleConfig.queue] || {}\n\n  const queueConfig: JobStatsScheduledRuns = {\n    ...existingQueuesConfig,\n  }\n  if (queueable.taskConfig) {\n    ;(queueConfig.tasks ??= {})[queueable.taskConfig.slug] = {\n      lastScheduledRun: getCurrentDate().toISOString(),\n    }\n  } else if (queueable.workflowConfig) {\n    ;(queueConfig.workflows ??= {})[queueable.workflowConfig.slug] = {\n      lastScheduledRun: getCurrentDate().toISOString(),\n    }\n  }\n\n  // Add to payload-jobs-stats global regardless of the status\n  if (jobStats) {\n    await req.payload.db.updateGlobal({\n      slug: jobStatsGlobalSlug,\n      data: {\n        ...(jobStats || {}),\n        stats: {\n          ...(jobStats?.stats || {}),\n          scheduledRuns: {\n            ...(jobStats?.stats?.scheduledRuns || {}),\n            queues: {\n              ...(jobStats?.stats?.scheduledRuns?.queues || {}),\n              [queueable.scheduleConfig.queue]: queueConfig,\n            },\n          },\n        },\n        updatedAt: new Date().toISOString(),\n      } as JobStats,\n      req,\n      returning: false,\n    })\n  } else {\n    await req.payload.db.createGlobal({\n      slug: jobStatsGlobalSlug,\n      data: {\n        createdAt: getCurrentDate().toISOString(),\n        stats: {\n          scheduledRuns: {\n            queues: {\n              [queueable.scheduleConfig.queue]: queueConfig,\n            },\n          },\n        },\n      } as JobStats,\n      req,\n      returning: false,\n    })\n  }\n}\n"],"names":["jobStatsGlobalSlug","getCurrentDate","defaultAfterSchedule","jobStats","queueable","req","existingQueuesConfig","stats","scheduledRuns","queues","scheduleConfig","queue","queueConfig","taskConfig","tasks","slug","lastScheduledRun","toISOString","workflowConfig","workflows","payload","db","updateGlobal","data","updatedAt","Date","returning","createGlobal","createdAt"],"mappings":";;;;AAEA,SAAwBA,kBAAkB,QAAQ,yBAAwB;AAC1E,SAASC,cAAc,QAAQ,oCAAmC;;;AAM3D,MAAMC,uBAAwC,OAAO,EAAEC,QAAQ,EAAEC,SAAS,EAAEC,GAAG,EAAE;IACtF,MAAMC,uBACJH,UAAUI,OAAOC,eAAeC,QAAQ,CAACL,UAAUM,cAAc,CAACC,KAAK,CAAC,IAAI,CAAC;IAE/E,MAAMC,cAAqC;QACzC,GAAGN,oBAAoB;IACzB;IACA,IAAIF,UAAUS,UAAU,EAAE;;QACtBD,CAAAA,YAAYE,KAAK,KAAK,CAAC,CAAA,CAAE,CAACV,UAAUS,UAAU,CAACE,IAAI,CAAC,GAAG;YACvDC,sBAAkBf,oSAAAA,IAAiBgB,WAAW;QAChD;IACF,OAAO,IAAIb,UAAUc,cAAc,EAAE;;QACjCN,CAAAA,YAAYO,SAAS,KAAK,CAAC,CAAA,CAAE,CAACf,UAAUc,cAAc,CAACH,IAAI,CAAC,GAAG;YAC/DC,sBAAkBf,oSAAAA,IAAiBgB,WAAW;QAChD;IACF;IAEA,4DAA4D;IAC5D,IAAId,UAAU;QACZ,MAAME,IAAIe,OAAO,CAACC,EAAE,CAACC,YAAY,CAAC;YAChCP,MAAMf,6RAAAA;YACNuB,MAAM;gBACJ,GAAIpB,YAAY,CAAC,CAAC;gBAClBI,OAAO;oBACL,GAAIJ,UAAUI,SAAS,CAAC,CAAC;oBACzBC,eAAe;wBACb,GAAIL,UAAUI,OAAOC,iBAAiB,CAAC,CAAC;wBACxCC,QAAQ;4BACN,GAAIN,UAAUI,OAAOC,eAAeC,UAAU,CAAC,CAAC;4BAChD,CAACL,UAAUM,cAAc,CAACC,KAAK,CAAC,EAAEC;wBACpC;oBACF;gBACF;gBACAY,WAAW,IAAIC,OAAOR,WAAW;YACnC;YACAZ;YACAqB,WAAW;QACb;IACF,OAAO;QACL,MAAMrB,IAAIe,OAAO,CAACC,EAAE,CAACM,YAAY,CAAC;YAChCZ,MAAMf,6RAAAA;YACNuB,MAAM;gBACJK,eAAW3B,oSAAAA,IAAiBgB,WAAW;gBACvCV,OAAO;oBACLC,eAAe;wBACbC,QAAQ;4BACN,CAACL,UAAUM,cAAc,CAACC,KAAK,CAAC,EAAEC;wBACpC;oBACF;gBACF;YACF;YACAP;YACAqB,WAAW;QACb;IACF;AACF,EAAC"}},
    {"offset": {"line": 270, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/handleSchedules/countRunnableOrActiveJobsForQueue.ts"],"sourcesContent":["import type { PayloadRequest, Where } from '../../../types/index.js'\nimport type { TaskType } from '../../config/types/taskTypes.js'\nimport type { WorkflowTypes } from '../../config/types/workflowTypes.js'\n\n/**\n * Gets all queued jobs that can be run. This means they either:\n * - failed but do not have a definitive error => can be retried\n * - are currently processing\n * - have not been started yet\n */\nexport async function countRunnableOrActiveJobsForQueue({\n  onlyScheduled = false,\n  queue,\n  req,\n  taskSlug,\n  workflowSlug,\n}: {\n  /**\n   * If true, this counts only jobs that have been created through the scheduling system.\n   *\n   * @default false\n   */\n  onlyScheduled?: boolean\n  queue: string\n  req: PayloadRequest\n  taskSlug?: TaskType\n  workflowSlug?: WorkflowTypes\n}): Promise<number> {\n  const and: Where[] = [\n    {\n      queue: {\n        equals: queue,\n      },\n    },\n\n    {\n      completedAt: { exists: false },\n    },\n    {\n      error: { exists: false },\n    },\n  ]\n\n  if (taskSlug) {\n    and.push({\n      taskSlug: {\n        equals: taskSlug,\n      },\n    })\n  } else if (workflowSlug) {\n    and.push({\n      workflowSlug: {\n        equals: workflowSlug,\n      },\n    })\n  }\n  if (onlyScheduled) {\n    and.push({\n      'meta.scheduled': {\n        equals: true,\n      },\n    })\n  }\n\n  const runnableOrActiveJobsForQueue = await req.payload.db.count({\n    collection: 'payload-jobs',\n    req,\n    where: {\n      and,\n    },\n  })\n\n  return runnableOrActiveJobsForQueue.totalDocs\n}\n"],"names":["countRunnableOrActiveJobsForQueue","onlyScheduled","queue","req","taskSlug","workflowSlug","and","equals","completedAt","exists","error","push","runnableOrActiveJobsForQueue","payload","db","count","collection","where","totalDocs"],"mappings":"AAIA;;;;;CAKC,GACD;;;;AAAO,eAAeA,kCAAkC,EACtDC,gBAAgB,KAAK,EACrBC,KAAK,EACLC,GAAG,EACHC,QAAQ,EACRC,YAAY,EAYb;IACC,MAAMC,MAAe;QACnB;YACEJ,OAAO;gBACLK,QAAQL;YACV;QACF;QAEA;YACEM,aAAa;gBAAEC,QAAQ;YAAM;QAC/B;QACA;YACEC,OAAO;gBAAED,QAAQ;YAAM;QACzB;KACD;IAED,IAAIL,UAAU;QACZE,IAAIK,IAAI,CAAC;YACPP,UAAU;gBACRG,QAAQH;YACV;QACF;IACF,OAAO,IAAIC,cAAc;QACvBC,IAAIK,IAAI,CAAC;YACPN,cAAc;gBACZE,QAAQF;YACV;QACF;IACF;IACA,IAAIJ,eAAe;QACjBK,IAAIK,IAAI,CAAC;YACP,kBAAkB;gBAChBJ,QAAQ;YACV;QACF;IACF;IAEA,MAAMK,+BAA+B,MAAMT,IAAIU,OAAO,CAACC,EAAE,CAACC,KAAK,CAAC;QAC9DC,YAAY;QACZb;QACAc,OAAO;YACLX;QACF;IACF;IAEA,OAAOM,6BAA6BM,SAAS;AAC/C"}},
    {"offset": {"line": 330, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/handleSchedules/defaultBeforeSchedule.ts"],"sourcesContent":["import type { BeforeScheduleFn } from '../../config/types/index.js'\n\nimport { countRunnableOrActiveJobsForQueue } from './countRunnableOrActiveJobsForQueue.js'\n\nexport const defaultBeforeSchedule: BeforeScheduleFn = async ({ queueable, req }) => {\n  // All tasks in that queue that are either currently processing or can be run\n  const runnableOrActiveJobsForQueue = await countRunnableOrActiveJobsForQueue({\n    onlyScheduled: true,\n    queue: queueable.scheduleConfig.queue,\n    req,\n    taskSlug: queueable.taskConfig?.slug,\n    workflowSlug: queueable.workflowConfig?.slug,\n  })\n\n  return {\n    input: {},\n    shouldSchedule: runnableOrActiveJobsForQueue === 0,\n    waitUntil: queueable.waitUntil,\n  }\n}\n"],"names":["countRunnableOrActiveJobsForQueue","defaultBeforeSchedule","queueable","req","runnableOrActiveJobsForQueue","onlyScheduled","queue","scheduleConfig","taskSlug","taskConfig","slug","workflowSlug","workflowConfig","input","shouldSchedule","waitUntil"],"mappings":";;;;AAEA,SAASA,iCAAiC,QAAQ,yCAAwC;;AAEnF,MAAMC,wBAA0C,OAAO,EAAEC,SAAS,EAAEC,GAAG,EAAE;IAC9E,6EAA6E;IAC7E,MAAMC,+BAA+B,UAAMJ,8VAAAA,EAAkC;QAC3EK,eAAe;QACfC,OAAOJ,UAAUK,cAAc,CAACD,KAAK;QACrCH;QACAK,UAAUN,UAAUO,UAAU,EAAEC;QAChCC,cAAcT,UAAUU,cAAc,EAAEF;IAC1C;IAEA,OAAO;QACLG,OAAO,CAAC;QACRC,gBAAgBV,iCAAiC;QACjDW,WAAWb,UAAUa,SAAS;IAChC;AACF,EAAC"}},
    {"offset": {"line": 355, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/handleSchedules/getQueuesWithSchedules.ts"],"sourcesContent":["import type { SanitizedJobsConfig, ScheduleConfig } from '../../config/types/index.js'\nimport type { TaskConfig } from '../../config/types/taskTypes.js'\nimport type { WorkflowConfig } from '../../config/types/workflowTypes.js'\n\ntype QueuesWithSchedules = {\n  [queue: string]: {\n    schedules: {\n      scheduleConfig: ScheduleConfig\n      taskConfig?: TaskConfig\n      workflowConfig?: WorkflowConfig\n    }[]\n  }\n}\n\nexport const getQueuesWithSchedules = ({\n  jobsConfig,\n}: {\n  jobsConfig: SanitizedJobsConfig\n}): QueuesWithSchedules => {\n  const tasksWithSchedules =\n    jobsConfig.tasks?.filter((task) => {\n      return task.schedule?.length\n    }) ?? []\n\n  const workflowsWithSchedules =\n    jobsConfig.workflows?.filter((workflow) => {\n      return workflow.schedule?.length\n    }) ?? []\n\n  const queuesWithSchedules: QueuesWithSchedules = {}\n\n  for (const task of tasksWithSchedules) {\n    for (const schedule of task.schedule ?? []) {\n      ;(queuesWithSchedules[schedule.queue] ??= { schedules: [] }).schedules.push({\n        scheduleConfig: schedule,\n        taskConfig: task,\n      })\n    }\n  }\n  for (const workflow of workflowsWithSchedules) {\n    for (const schedule of workflow.schedule ?? []) {\n      ;(queuesWithSchedules[schedule.queue] ??= { schedules: [] }).schedules.push({\n        scheduleConfig: schedule,\n        workflowConfig: workflow,\n      })\n    }\n  }\n\n  return queuesWithSchedules\n}\n"],"names":["getQueuesWithSchedules","jobsConfig","tasksWithSchedules","tasks","filter","task","schedule","length","workflowsWithSchedules","workflows","workflow","queuesWithSchedules","queue","schedules","push","scheduleConfig","taskConfig","workflowConfig"],"mappings":";;;;AAcO,MAAMA,yBAAyB,CAAC,EACrCC,UAAU,EAGX;IACC,MAAMC,qBACJD,WAAWE,KAAK,EAAEC,OAAO,CAACC;QACxB,OAAOA,KAAKC,QAAQ,EAAEC;IACxB,MAAM,EAAE;IAEV,MAAMC,yBACJP,WAAWQ,SAAS,EAAEL,OAAO,CAACM;QAC5B,OAAOA,SAASJ,QAAQ,EAAEC;IAC5B,MAAM,EAAE;IAEV,MAAMI,sBAA2C,CAAC;IAElD,KAAK,MAAMN,QAAQH,mBAAoB;QACrC,KAAK,MAAMI,YAAYD,KAAKC,QAAQ,IAAI,EAAE,CAAE;;YACxCK,CAAAA,mBAAmB,CAACL,SAASM,KAAK,CAAC,KAAK;gBAAEC,WAAW,EAAE;YAAC,CAAA,EAAGA,SAAS,CAACC,IAAI,CAAC;gBAC1EC,gBAAgBT;gBAChBU,YAAYX;YACd;QACF;IACF;IACA,KAAK,MAAMK,YAAYF,uBAAwB;QAC7C,KAAK,MAAMF,YAAYI,SAASJ,QAAQ,IAAI,EAAE,CAAE;;YAC5CK,CAAAA,mBAAmB,CAACL,SAASM,KAAK,CAAC,KAAK;gBAAEC,WAAW,EAAE;YAAC,CAAA,EAAGA,SAAS,CAACC,IAAI,CAAC;gBAC1EC,gBAAgBT;gBAChBW,gBAAgBP;YAClB;QACF;IACF;IAEA,OAAOC;AACT,EAAC"}},
    {"offset": {"line": 395, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/handleSchedules/index.ts"],"sourcesContent":["import { Cron } from 'croner'\n\nimport type { Job, TaskConfig, WorkflowConfig } from '../../../index.js'\nimport type { PayloadRequest } from '../../../types/index.js'\nimport type { BeforeScheduleFn, Queueable, ScheduleConfig } from '../../config/types/index.js'\n\nimport { type JobStats, jobStatsGlobalSlug } from '../../config/global.js'\nimport { defaultAfterSchedule } from './defaultAfterSchedule.js'\nimport { defaultBeforeSchedule } from './defaultBeforeSchedule.js'\nimport { getQueuesWithSchedules } from './getQueuesWithSchedules.js'\n\nexport type HandleSchedulesResult = {\n  errored: Queueable[]\n  queued: Queueable[]\n  skipped: Queueable[]\n}\n\n/**\n * On vercel, we cannot auto-schedule jobs using a Cron - instead, we'll use this same endpoint that can\n * also be called from Vercel Cron for auto-running jobs.\n *\n * The benefit of doing it like this instead of a separate endpoint is that we can run jobs immediately\n * after they are scheduled\n */\nexport async function handleSchedules({\n  allQueues = false,\n  queue: _queue,\n  req,\n}: {\n  /**\n   * If you want to schedule jobs from all queues, set this to true.\n   * If you set this to true, the `queue` property will be ignored.\n   *\n   * @default false\n   */\n  allQueues?: boolean\n  /**\n   * If you want to only schedule jobs that are set to schedule in a specific queue, set this to the queue name.\n   *\n   * @default jobs from the `default` queue will be executed.\n   */\n  queue?: string\n  req: PayloadRequest\n}): Promise<HandleSchedulesResult> {\n  const queue = _queue ?? 'default'\n  const jobsConfig = req.payload.config.jobs\n  const queuesWithSchedules = getQueuesWithSchedules({\n    jobsConfig,\n  })\n\n  if (Object.keys(queuesWithSchedules).length === 0) {\n    // No schedules defined => return early, before fetching jobsStatsGlobal, as the global may not even exist\n    return {\n      errored: [],\n      queued: [],\n      skipped: [],\n    }\n  }\n\n  const stats: JobStats = await req.payload.db.findGlobal({\n    slug: jobStatsGlobalSlug,\n    req,\n  })\n\n  /**\n   * Almost last step! Tasks and Workflows added here just need to be constraint-checked (e.g max. 1 running task etc.),\n   * before we can queue them\n   */\n  const queueables: Queueable[] = []\n\n  // Need to know when that particular job was last scheduled in that particular queue\n\n  for (const [queueName, { schedules }] of Object.entries(queuesWithSchedules)) {\n    if (!allQueues && queueName !== queue) {\n      // If a queue is specified, only schedule jobs for that queue\n      continue\n    }\n    for (const schedulable of schedules) {\n      const queuable = checkQueueableTimeConstraints({\n        queue: queueName,\n        scheduleConfig: schedulable.scheduleConfig,\n        stats,\n        taskConfig: schedulable.taskConfig,\n        workflowConfig: schedulable.workflowConfig,\n      })\n      if (queuable) {\n        queueables.push(queuable)\n      }\n    }\n  }\n\n  const queued: Queueable[] = []\n  const skipped: Queueable[] = []\n  const errored: Queueable[] = []\n\n  /**\n   * Now queue, but check for constraints (= beforeSchedule) first.\n   * Default constraint (= defaultBeforeSchedule): max. 1 running / scheduled task or workflow per queue\n   */\n  for (const queueable of queueables) {\n    const { status } = await scheduleQueueable({\n      queueable,\n      req,\n      stats,\n    })\n    switch (status) {\n      case 'error':\n        errored.push(queueable)\n        break\n      case 'skipped':\n        skipped.push(queueable)\n        break\n      case 'success':\n        queued.push(queueable)\n        break\n    }\n  }\n  return {\n    errored,\n    queued,\n    skipped,\n  }\n}\n\nexport function checkQueueableTimeConstraints({\n  queue,\n  scheduleConfig,\n  stats,\n  taskConfig,\n  workflowConfig,\n}: {\n  queue: string\n  scheduleConfig: ScheduleConfig\n  stats: JobStats\n  taskConfig?: TaskConfig\n  workflowConfig?: WorkflowConfig\n}): false | Queueable {\n  const queueScheduleStats = stats?.stats?.scheduledRuns?.queues?.[queue]\n\n  const lastScheduledRun = taskConfig\n    ? queueScheduleStats?.tasks?.[taskConfig.slug]?.lastScheduledRun\n    : queueScheduleStats?.workflows?.[workflowConfig?.slug ?? '']?.lastScheduledRun\n\n  const nextRun = new Cron(scheduleConfig.cron).nextRun(lastScheduledRun ?? undefined)\n\n  if (!nextRun) {\n    return false\n  }\n  return {\n    scheduleConfig,\n    taskConfig,\n    waitUntil: nextRun,\n    workflowConfig,\n  }\n}\n\nexport async function scheduleQueueable({\n  queueable,\n  req,\n  stats,\n}: {\n  queueable: Queueable\n  req: PayloadRequest\n  stats: JobStats\n}): Promise<{\n  job?: Job<false>\n  status: 'error' | 'skipped' | 'success'\n}> {\n  if (!queueable.taskConfig && !queueable.workflowConfig) {\n    return {\n      status: 'error',\n    }\n  }\n\n  const beforeScheduleFn = queueable.scheduleConfig.hooks?.beforeSchedule\n  const afterScheduleFN = queueable.scheduleConfig.hooks?.afterSchedule\n\n  try {\n    const beforeScheduleResult: Awaited<ReturnType<BeforeScheduleFn>> = await (\n      beforeScheduleFn ?? defaultBeforeSchedule\n    )({\n      // @ts-expect-error we know defaultBeforeSchedule will never call itself => pass null\n      defaultBeforeSchedule: beforeScheduleFn ? defaultBeforeSchedule : null,\n      jobStats: stats,\n      queueable,\n      req,\n    })\n\n    if (!beforeScheduleResult.shouldSchedule) {\n      await (afterScheduleFN ?? defaultAfterSchedule)({\n        // @ts-expect-error we know defaultAfterchedule will never call itself => pass null\n        defaultAfterSchedule: afterScheduleFN ? defaultAfterSchedule : null,\n        jobStats: stats,\n        queueable,\n        req,\n        status: 'skipped',\n      })\n      return {\n        status: 'skipped',\n      }\n    }\n\n    const job = (await req.payload.jobs.queue({\n      input: beforeScheduleResult.input ?? {},\n      meta: {\n        scheduled: true,\n      },\n      queue: queueable.scheduleConfig.queue,\n      req,\n      task: queueable?.taskConfig?.slug,\n      waitUntil: beforeScheduleResult.waitUntil,\n      workflow: queueable.workflowConfig?.slug,\n    } as Parameters<typeof req.payload.jobs.queue>[0])) as unknown as Job<false>\n\n    await (afterScheduleFN ?? defaultAfterSchedule)({\n      // @ts-expect-error we know defaultAfterchedule will never call itself => pass null\n      defaultAfterSchedule: afterScheduleFN ? defaultAfterSchedule : null,\n      job,\n      jobStats: stats,\n      queueable,\n      req,\n      status: 'success',\n    })\n    return {\n      status: 'success',\n    }\n  } catch (error) {\n    await (afterScheduleFN ?? defaultAfterSchedule)({\n      // @ts-expect-error we know defaultAfterchedule will never call itself => pass null\n      defaultAfterSchedule: afterScheduleFN ? defaultAfterSchedule : null,\n      error: error as Error,\n      jobStats: stats,\n      queueable,\n      req,\n      status: 'error',\n    })\n    return {\n      status: 'error',\n    }\n  }\n}\n"],"names":["Cron","jobStatsGlobalSlug","defaultAfterSchedule","defaultBeforeSchedule","getQueuesWithSchedules","handleSchedules","allQueues","queue","_queue","req","jobsConfig","payload","config","jobs","queuesWithSchedules","Object","keys","length","errored","queued","skipped","stats","db","findGlobal","slug","queueables","queueName","schedules","entries","schedulable","queuable","checkQueueableTimeConstraints","scheduleConfig","taskConfig","workflowConfig","push","queueable","status","scheduleQueueable","queueScheduleStats","scheduledRuns","queues","lastScheduledRun","tasks","workflows","nextRun","cron","undefined","waitUntil","beforeScheduleFn","hooks","beforeSchedule","afterScheduleFN","afterSchedule","beforeScheduleResult","jobStats","shouldSchedule","job","input","meta","scheduled","task","workflow","error"],"mappings":";;;;;;;;AAAA,SAASA,IAAI,QAAQ,SAAQ;AAM7B,SAAwBC,kBAAkB,QAAQ,yBAAwB;AAC1E,SAASC,oBAAoB,QAAQ,4BAA2B;AAChE,SAASC,qBAAqB,QAAQ,6BAA4B;AAClE,SAASC,sBAAsB,QAAQ,8BAA6B;;;;;;AAe7D,eAAeC,gBAAgB,EACpCC,YAAY,KAAK,EACjBC,OAAOC,MAAM,EACbC,GAAG,EAgBJ;IACC,MAAMF,QAAQC,UAAU;IACxB,MAAME,aAAaD,IAAIE,OAAO,CAACC,MAAM,CAACC,IAAI;IAC1C,MAAMC,0BAAsBV,wUAAAA,EAAuB;QACjDM;IACF;IAEA,IAAIK,OAAOC,IAAI,CAACF,qBAAqBG,MAAM,KAAK,GAAG;QACjD,0GAA0G;QAC1G,OAAO;YACLC,SAAS,EAAE;YACXC,QAAQ,EAAE;YACVC,SAAS,EAAE;QACb;IACF;IAEA,MAAMC,QAAkB,MAAMZ,IAAIE,OAAO,CAACW,EAAE,CAACC,UAAU,CAAC;QACtDC,MAAMvB,6RAAAA;QACNQ;IACF;IAEA;;;GAGC,GACD,MAAMgB,aAA0B,EAAE;IAElC,oFAAoF;IAEpF,KAAK,MAAM,CAACC,WAAW,EAAEC,SAAS,EAAE,CAAC,IAAIZ,OAAOa,OAAO,CAACd,qBAAsB;QAC5E,IAAI,CAACR,aAAaoB,cAAcnB,OAAO;YAErC;QACF;QACA,KAAK,MAAMsB,eAAeF,UAAW;YACnC,MAAMG,WAAWC,8BAA8B;gBAC7CxB,OAAOmB;gBACPM,gBAAgBH,YAAYG,cAAc;gBAC1CX;gBACAY,YAAYJ,YAAYI,UAAU;gBAClCC,gBAAgBL,YAAYK,cAAc;YAC5C;YACA,IAAIJ,UAAU;gBACZL,WAAWU,IAAI,CAACL;YAClB;QACF;IACF;IAEA,MAAMX,SAAsB,EAAE;IAC9B,MAAMC,UAAuB,EAAE;IAC/B,MAAMF,UAAuB,EAAE;IAE/B;;;GAGC,GACD,KAAK,MAAMkB,aAAaX,WAAY;QAClC,MAAM,EAAEY,MAAM,EAAE,GAAG,MAAMC,kBAAkB;YACzCF;YACA3B;YACAY;QACF;QACA,OAAQgB;YACN,KAAK;gBACHnB,QAAQiB,IAAI,CAACC;gBACb;YACF,KAAK;gBACHhB,QAAQe,IAAI,CAACC;gBACb;YACF,KAAK;gBACHjB,OAAOgB,IAAI,CAACC;gBACZ;QACJ;IACF;IACA,OAAO;QACLlB;QACAC;QACAC;IACF;AACF;AAEO,SAASW,8BAA8B,EAC5CxB,KAAK,EACLyB,cAAc,EACdX,KAAK,EACLY,UAAU,EACVC,cAAc,EAOf;IACC,MAAMK,qBAAqBlB,OAAOA,OAAOmB,eAAeC,QAAQ,CAAClC,MAAM;IAEvE,MAAMmC,mBAAmBT,aACrBM,oBAAoBI,OAAO,CAACV,WAAWT,IAAI,CAAC,EAAEkB,mBAC9CH,oBAAoBK,WAAW,CAACV,gBAAgBV,QAAQ,GAAG,EAAEkB;IAEjE,MAAMG,UAAU,IAAI7C,qMAAAA,CAAKgC,eAAec,IAAI,EAAED,OAAO,CAACH,oBAAoBK;IAE1E,IAAI,CAACF,SAAS;QACZ,OAAO;IACT;IACA,OAAO;QACLb;QACAC;QACAe,WAAWH;QACXX;IACF;AACF;AAEO,eAAeI,kBAAkB,EACtCF,SAAS,EACT3B,GAAG,EACHY,KAAK,EAKN;IAIC,IAAI,CAACe,UAAUH,UAAU,IAAI,CAACG,UAAUF,cAAc,EAAE;QACtD,OAAO;YACLG,QAAQ;QACV;IACF;IAEA,MAAMY,mBAAmBb,UAAUJ,cAAc,CAACkB,KAAK,EAAEC;IACzD,MAAMC,kBAAkBhB,UAAUJ,cAAc,CAACkB,KAAK,EAAEG;IAExD,IAAI;QACF,MAAMC,uBAA8D,MAClEL,CAAAA,oBAAoB9C,sUAAoB,EACxC;YACA,qFAAqF;YACrFA,uBAAuB8C,mBAAmB9C,sUAAAA,GAAwB;YAClEoD,UAAUlC;YACVe;YACA3B;QACF;QAEA,IAAI,CAAC6C,qBAAqBE,cAAc,EAAE;YACxC,MAAOJ,CAAAA,mBAAmBlD,oUAAmB,EAAG;gBAC9C,mFAAmF;gBACnFA,sBAAsBkD,kBAAkBlD,oUAAAA,GAAuB;gBAC/DqD,UAAUlC;gBACVe;gBACA3B;gBACA4B,QAAQ;YACV;YACA,OAAO;gBACLA,QAAQ;YACV;QACF;QAEA,MAAMoB,MAAO,MAAMhD,IAAIE,OAAO,CAACE,IAAI,CAACN,KAAK,CAAC;YACxCmD,OAAOJ,qBAAqBI,KAAK,IAAI,CAAC;YACtCC,MAAM;gBACJC,WAAW;YACb;YACArD,OAAO6B,UAAUJ,cAAc,CAACzB,KAAK;YACrCE;YACAoD,MAAMzB,WAAWH,YAAYT;YAC7BwB,WAAWM,qBAAqBN,SAAS;YACzCc,UAAU1B,UAAUF,cAAc,EAAEV;QACtC;QAEA,MAAO4B,CAAAA,mBAAmBlD,oUAAmB,EAAG;YAC9C,mFAAmF;YACnFA,sBAAsBkD,kBAAkBlD,oUAAAA,GAAuB;YAC/DuD;YACAF,UAAUlC;YACVe;YACA3B;YACA4B,QAAQ;QACV;QACA,OAAO;YACLA,QAAQ;QACV;IACF,EAAE,OAAO0B,OAAO;QACd,MAAOX,CAAAA,mBAAmBlD,oUAAmB,EAAG;YAC9C,mFAAmF;YACnFA,sBAAsBkD,kBAAkBlD,oUAAAA,GAAuB;YAC/D6D,OAAOA;YACPR,UAAUlC;YACVe;YACA3B;YACA4B,QAAQ;QACV;QACA,OAAO;YACLA,QAAQ;QACV;IACF;AACF"}},
    {"offset": {"line": 568, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/errors/index.ts"],"sourcesContent":["import type { Job, SingleTaskStatus, WorkflowConfig } from '../../index.js'\nimport type { RetryConfig, TaskConfig } from '../config/types/taskTypes.js'\nimport type { TaskParent } from '../operations/runJobs/runJob/getRunTaskFunction.js'\n\nexport type TaskErrorArgs = {\n  executedAt: Date\n  input?: object\n  job: Job\n  message: string\n  output?: object\n  parent?: TaskParent\n  retriesConfig: RetryConfig\n  taskConfig?: TaskConfig<string>\n  taskID: string\n  taskSlug: string\n  taskStatus: null | SingleTaskStatus<string>\n  workflowConfig: WorkflowConfig\n}\n\nexport type WorkflowErrorArgs = {\n  job: Job\n  message: string\n  workflowConfig: WorkflowConfig\n}\n\nexport class TaskError extends Error {\n  args: TaskErrorArgs\n  constructor(args: TaskErrorArgs) {\n    super(args.message)\n    this.args = args\n  }\n}\nexport class WorkflowError extends Error {\n  args: WorkflowErrorArgs\n\n  constructor(args: WorkflowErrorArgs) {\n    super(args.message)\n    this.args = args\n  }\n}\n\nexport class JobCancelledError extends Error {\n  args: {\n    job: Job\n  }\n\n  constructor(args: { job: Job }) {\n    super(`Job ${args.job.id} was cancelled`)\n    this.args = args\n  }\n}\n"],"names":["TaskError","Error","args","constructor","message","WorkflowError","JobCancelledError","job","id"],"mappings":";;;;;;;;AAyBO,MAAMA,kBAAkBC;IAC7BC,KAAmB;IACnBC,YAAYD,IAAmB,CAAE;QAC/B,KAAK,CAACA,KAAKE,OAAO;QAClB,IAAI,CAACF,IAAI,GAAGA;IACd;AACF;AACO,MAAMG,sBAAsBJ;IACjCC,KAAuB;IAEvBC,YAAYD,IAAuB,CAAE;QACnC,KAAK,CAACA,KAAKE,OAAO;QAClB,IAAI,CAACF,IAAI,GAAGA;IACd;AACF;AAEO,MAAMI,0BAA0BL;IACrCC,KAEC;IAEDC,YAAYD,IAAkB,CAAE;QAC9B,KAAK,CAAC,CAAC,IAAI,EAAEA,KAAKK,GAAG,CAACC,EAAE,CAAC,cAAc,CAAC;QACxC,IAAI,CAACN,IAAI,GAAGA;IACd;AACF"}},
    {"offset": {"line": 601, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/utilities/updateJob.ts"],"sourcesContent":["import type { ManyOptions } from '../../collections/operations/local/update.js'\nimport type { UpdateJobsArgs } from '../../database/types.js'\nimport type { Job } from '../../index.js'\nimport type { PayloadRequest, Sort, Where } from '../../types/index.js'\n\nimport { jobAfterRead, jobsCollectionSlug } from '../config/collection.js'\n\ntype BaseArgs = {\n  data: Partial<Job>\n  depth?: number\n  disableTransaction?: boolean\n  limit?: number\n  req: PayloadRequest\n  returning?: boolean\n}\n\ntype ArgsByID = {\n  id: number | string\n  limit?: never\n  sort?: never\n  where?: never\n}\n\ntype ArgsWhere = {\n  id?: never\n  limit?: number\n  sort?: Sort\n  where: Where\n}\n\ntype RunJobsArgs = (ArgsByID | ArgsWhere) & BaseArgs\n\n/**\n * Convenience method for updateJobs by id\n */\nexport async function updateJob(args: ArgsByID & BaseArgs) {\n  const result = await updateJobs(args)\n  if (result) {\n    return result[0]\n  }\n}\n\n/**\n * Helper for updating jobs in the most performant way possible.\n * Handles deciding whether it can used direct db methods or not, and if so,\n * manually runs the afterRead hook that populates the `taskStatus` property.\n */\nexport async function updateJobs({\n  id,\n  data,\n  depth,\n  disableTransaction,\n  limit: limitArg,\n  req,\n  returning,\n  sort,\n  where: whereArg,\n}: RunJobsArgs): Promise<Job[] | null> {\n  const limit = id ? 1 : limitArg\n  const where = id ? { id: { equals: id } } : whereArg\n\n  if (depth || req.payload.config?.jobs?.runHooks) {\n    const result = await req.payload.update({\n      id,\n      collection: jobsCollectionSlug,\n      data,\n      depth,\n      disableTransaction,\n      limit,\n      req,\n      where,\n    } as ManyOptions<any, any>)\n    if (returning === false || !result) {\n      return null\n    }\n    return result.docs as Job[]\n  }\n\n  const jobReq = {\n    transactionID:\n      req.payload.db.name !== 'mongoose'\n        ? ((await req.payload.db.beginTransaction()) as string)\n        : undefined,\n  }\n\n  if (typeof data.updatedAt === 'undefined') {\n    // Ensure updatedAt date is always updated\n    data.updatedAt = new Date().toISOString()\n  }\n\n  const args: UpdateJobsArgs = id\n    ? {\n        id,\n        data,\n        req: jobReq,\n        returning,\n      }\n    : {\n        data,\n        limit,\n        req: jobReq,\n        returning,\n        sort,\n        where: where as Where,\n      }\n\n  const updatedJobs: Job[] | null = await req.payload.db.updateJobs(args)\n\n  if (req.payload.db.name !== 'mongoose' && jobReq.transactionID) {\n    await req.payload.db.commitTransaction(jobReq.transactionID)\n  }\n\n  if (returning === false || !updatedJobs?.length) {\n    return null\n  }\n\n  return updatedJobs.map((updatedJob) => {\n    return jobAfterRead({\n      config: req.payload.config,\n      doc: updatedJob,\n    })\n  })\n}\n"],"names":["jobAfterRead","jobsCollectionSlug","updateJob","args","result","updateJobs","id","data","depth","disableTransaction","limit","limitArg","req","returning","sort","where","whereArg","equals","payload","config","jobs","runHooks","update","collection","docs","jobReq","transactionID","db","name","beginTransaction","undefined","updatedAt","Date","toISOString","updatedJobs","commitTransaction","length","map","updatedJob","doc"],"mappings":";;;;;;AAKA,SAASA,YAAY,EAAEC,kBAAkB,QAAQ,0BAAyB;;AA8BnE,eAAeC,UAAUC,IAAyB;IACvD,MAAMC,SAAS,MAAMC,WAAWF;IAChC,IAAIC,QAAQ;QACV,OAAOA,MAAM,CAAC,EAAE;IAClB;AACF;AAOO,eAAeC,WAAW,EAC/BC,EAAE,EACFC,IAAI,EACJC,KAAK,EACLC,kBAAkB,EAClBC,OAAOC,QAAQ,EACfC,GAAG,EACHC,SAAS,EACTC,IAAI,EACJC,OAAOC,QAAQ,EACH;IACZ,MAAMN,QAAQJ,KAAK,IAAIK;IACvB,MAAMI,QAAQT,KAAK;QAAEA,IAAI;YAAEW,QAAQX;QAAG;IAAE,IAAIU;IAE5C,IAAIR,SAASI,IAAIM,OAAO,CAACC,MAAM,EAAEC,MAAMC,UAAU;QAC/C,MAAMjB,SAAS,MAAMQ,IAAIM,OAAO,CAACI,MAAM,CAAC;YACtChB;YACAiB,YAAYtB,iSAAAA;YACZM;YACAC;YACAC;YACAC;YACAE;YACAG;QACF;QACA,IAAIF,cAAc,SAAS,CAACT,QAAQ;YAClC,OAAO;QACT;QACA,OAAOA,OAAOoB,IAAI;IACpB;IAEA,MAAMC,SAAS;QACbC,eACEd,IAAIM,OAAO,CAACS,EAAE,CAACC,IAAI,KAAK,aAClB,MAAMhB,IAAIM,OAAO,CAACS,EAAE,CAACE,gBAAgB,KACvCC;IACR;IAEA,IAAI,OAAOvB,KAAKwB,SAAS,KAAK,aAAa;QACzC,0CAA0C;QAC1CxB,KAAKwB,SAAS,GAAG,IAAIC,OAAOC,WAAW;IACzC;IAEA,MAAM9B,OAAuBG,KACzB;QACEA;QACAC;QACAK,KAAKa;QACLZ;IACF,IACA;QACEN;QACAG;QACAE,KAAKa;QACLZ;QACAC;QACAC,OAAOA;IACT;IAEJ,MAAMmB,cAA4B,MAAMtB,IAAIM,OAAO,CAACS,EAAE,CAACtB,UAAU,CAACF;IAElE,IAAIS,IAAIM,OAAO,CAACS,EAAE,CAACC,IAAI,KAAK,cAAcH,OAAOC,aAAa,EAAE;QAC9D,MAAMd,IAAIM,OAAO,CAACS,EAAE,CAACQ,iBAAiB,CAACV,OAAOC,aAAa;IAC7D;IAEA,IAAIb,cAAc,SAAS,CAACqB,aAAaE,QAAQ;QAC/C,OAAO;IACT;IAEA,OAAOF,YAAYG,GAAG,CAAC,CAACC;QACtB,WAAOtC,2RAAAA,EAAa;YAClBmB,QAAQP,IAAIM,OAAO,CAACC,MAAM;YAC1BoB,KAAKD;QACP;IACF;AACF"}},
    {"offset": {"line": 676, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/runJobs/runJob/getUpdateJobFunction.ts"],"sourcesContent":["import type { Job } from '../../../../index.js'\nimport type { PayloadRequest } from '../../../../types/index.js'\n\nimport { JobCancelledError } from '../../../errors/index.js'\nimport { updateJob } from '../../../utilities/updateJob.js'\n\nexport type UpdateJobFunction = (jobData: Partial<Job>) => Promise<Job>\n\n/**\n * Helper for updating a job that does the following, additionally to updating the job:\n * - Merges incoming data from the updated job into the original job object\n * - Handles job cancellation by throwing a `JobCancelledError` if the job was cancelled.\n */\nexport function getUpdateJobFunction(job: Job, req: PayloadRequest): UpdateJobFunction {\n  return async (jobData) => {\n    const updatedJob = await updateJob({\n      id: job.id,\n      data: jobData,\n      depth: req.payload.config.jobs.depth,\n      disableTransaction: true,\n      req,\n    })\n\n    if (!updatedJob) {\n      return job\n    }\n\n    // Update job object like this to modify the original object - that way, incoming changes (e.g. taskStatus field that will be re-generated through the hook) will be reflected in the calling function\n    for (const key in updatedJob) {\n      if (key === 'log') {\n        // Add all new log entries to the original job.log object. Do not delete any existing log entries.\n        // Do not update existing log entries, as existing log entries should be immutable.\n        for (const logEntry of updatedJob?.log ?? []) {\n          if (!job.log || !job.log.some((entry) => entry.id === logEntry.id)) {\n            ;(job.log ??= []).push(logEntry)\n          }\n        }\n      } else {\n        ;(job as any)[key] = updatedJob[key as keyof Job]\n      }\n    }\n\n    if ((updatedJob?.error as Record<string, unknown>)?.cancelled) {\n      throw new JobCancelledError({ job })\n    }\n\n    return updatedJob\n  }\n}\n"],"names":["JobCancelledError","updateJob","getUpdateJobFunction","job","req","jobData","updatedJob","id","data","depth","payload","config","jobs","disableTransaction","key","logEntry","log","some","entry","push","error","cancelled"],"mappings":";;;;AAGA,SAASA,iBAAiB,QAAQ,2BAA0B;AAC5D,SAASC,SAAS,QAAQ,kCAAiC;;;AASpD,SAASC,qBAAqBC,GAAQ,EAAEC,GAAmB;IAChE,OAAO,OAAOC;QACZ,MAAMC,aAAa,UAAML,0RAAAA,EAAU;YACjCM,IAAIJ,IAAII,EAAE;YACVC,MAAMH;YACNI,OAAOL,IAAIM,OAAO,CAACC,MAAM,CAACC,IAAI,CAACH,KAAK;YACpCI,oBAAoB;YACpBT;QACF;QAEA,IAAI,CAACE,YAAY;YACf,OAAOH;QACT;QAEA,sMAAsM;QACtM,IAAK,MAAMW,OAAOR,WAAY;YAC5B,IAAIQ,QAAQ,OAAO;gBACjB,kGAAkG;gBAClG,mFAAmF;gBACnF,KAAK,MAAMC,YAAYT,YAAYU,OAAO,EAAE,CAAE;oBAC5C,IAAI,CAACb,IAAIa,GAAG,IAAI,CAACb,IAAIa,GAAG,CAACC,IAAI,CAAC,CAACC,QAAUA,MAAMX,EAAE,KAAKQ,SAASR,EAAE,GAAG;;wBAChEJ,CAAAA,IAAIa,GAAG,KAAK,EAAC,EAAGG,IAAI,CAACJ;oBACzB;gBACF;YACF,OAAO;;gBACHZ,GAAW,CAACW,IAAI,GAAGR,UAAU,CAACQ,IAAiB;YACnD;QACF;QAEA,IAAKR,YAAYc,OAAmCC,WAAW;YAC7D,MAAM,IAAIrB,2RAAAA,CAAkB;gBAAEG;YAAI;QACpC;QAEA,OAAOG;IACT;AACF"}},
    {"offset": {"line": 724, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/runJobs/runJob/importHandlerPath.ts"],"sourcesContent":["import { pathToFileURL } from 'url'\n\nimport type { TaskConfig, TaskHandler, TaskType } from '../../../config/types/taskTypes.js'\n\n/**\n * Imports a handler function from a given path.\n */\nexport async function importHandlerPath<T>(path: string): Promise<T> {\n  let runner!: T\n  const [runnerPath, runnerImportName] = path.split('#')\n\n  let runnerModule\n  try {\n    // We need to check for `require` for compatibility with outdated frameworks that do not\n    // properly support ESM, like Jest. This is not done to support projects without \"type\": \"module\" set\n    runnerModule =\n      typeof require === 'function'\n        ? await eval(`require('${runnerPath!.replaceAll('\\\\', '/')}')`)\n        : await eval(`import('${pathToFileURL(runnerPath!).href}')`)\n  } catch (e) {\n    throw new Error(\n      `Error importing job queue handler module for path ${path}. This is an advanced feature that may require a sophisticated build pipeline, especially when using it in production or within Next.js, e.g. by calling opening the /api/payload-jobs/run endpoint. You will have to transpile the handler files separately and ensure they are available in the same location when the job is run. If you're using an endpoint to execute your jobs, it's recommended to define your handlers as functions directly in your Payload Config, or use import paths handlers outside of Next.js. Import Error: \\n${e instanceof Error ? e.message : 'Unknown error'}`,\n    )\n  }\n\n  // If the path has indicated an #exportName, try to get it\n  if (runnerImportName && runnerModule[runnerImportName]) {\n    runner = runnerModule[runnerImportName]\n  }\n\n  // If there is a default export, use it\n  if (!runner && runnerModule.default) {\n    runner = runnerModule.default\n  }\n\n  // Finally, use whatever was imported\n  if (!runner) {\n    runner = runnerModule\n  }\n\n  return runner\n}\n\n/**\n * The `handler` property of a task config can either be a function or a path to a module that exports a function.\n * This function resolves the handler to a function, either by importing it from the path or returning the function directly\n * if it is already a function.\n */\nexport async function getTaskHandlerFromConfig(taskConfig?: TaskConfig) {\n  if (!taskConfig) {\n    throw new Error('Task config is required to get the task handler')\n  }\n  if (typeof taskConfig.handler === 'function') {\n    return taskConfig.handler\n  } else {\n    return await importHandlerPath<TaskHandler<TaskType>>(taskConfig.handler)\n  }\n}\n"],"names":["pathToFileURL","importHandlerPath","path","runner","runnerPath","runnerImportName","split","runnerModule","require","eval","replaceAll","href","e","Error","message","default","getTaskHandlerFromConfig","taskConfig","handler"],"mappings":";;;;;;AAAA,SAASA,aAAa,QAAQ,MAAK;;AAO5B,eAAeC,kBAAqBC,IAAY;IACrD,IAAIC;IACJ,MAAM,CAACC,YAAYC,iBAAiB,GAAGH,KAAKI,KAAK,CAAC;IAElD,IAAIC;IACJ,IAAI;QACF,wFAAwF;QACxF,qGAAqG;QACrGA,eACE,OAAOC,YAAY,oBACf,MAAMC,KAAK,CAAC,SAAS,EAAEL,WAAYM,UAAU,CAAC,MAAM,KAAK,EAAE,CAAC,IAC5D,MAAMD,KAAK,CAAC,QAAQ,EAAET,cAAcI,YAAaO,IAAI,CAAC,EAAE,CAAC;IACjE,EAAE,OAAOC,GAAG;QACV,MAAM,IAAIC,MACR,CAAC,kDAAkD,EAAEX,KAAK,+gBAA+gB,EAAEU,aAAaC,QAAQD,EAAEE,OAAO,GAAG,iBAAiB;IAEjoB;IAEA,0DAA0D;IAC1D,IAAIT,oBAAoBE,YAAY,CAACF,iBAAiB,EAAE;QACtDF,SAASI,YAAY,CAACF,iBAAiB;IACzC;IAEA,uCAAuC;IACvC,IAAI,CAACF,UAAUI,aAAaQ,OAAO,EAAE;QACnCZ,SAASI,aAAaQ,OAAO;IAC/B;IAEA,qCAAqC;IACrC,IAAI,CAACZ,QAAQ;QACXA,SAASI;IACX;IAEA,OAAOJ;AACT;AAOO,eAAea,yBAAyBC,UAAuB;IACpE,IAAI,CAACA,YAAY;QACf,MAAM,IAAIJ,MAAM;IAClB;IACA,IAAI,OAAOI,WAAWC,OAAO,KAAK,YAAY;QAC5C,OAAOD,WAAWC,OAAO;IAC3B,OAAO;QACL,OAAO,MAAMjB,kBAAyCgB,WAAWC,OAAO;IAC1E;AACF"}},
    {"offset": {"line": 771, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/errors/calculateBackoffWaitUntil.ts"],"sourcesContent":["import type { RetryConfig } from '../config/types/taskTypes.js'\n\nimport { getCurrentDate } from '../utilities/getCurrentDate.js'\n\nexport function calculateBackoffWaitUntil({\n  retriesConfig,\n  totalTried,\n}: {\n  retriesConfig: number | RetryConfig\n  totalTried: number\n}): Date {\n  let waitUntil: Date = getCurrentDate()\n  if (typeof retriesConfig === 'object') {\n    if (retriesConfig.backoff) {\n      if (retriesConfig.backoff.type === 'fixed') {\n        waitUntil = retriesConfig.backoff.delay\n          ? new Date(getCurrentDate().getTime() + retriesConfig.backoff.delay)\n          : getCurrentDate()\n      } else if (retriesConfig.backoff.type === 'exponential') {\n        // 2 ^ (attempts - 1) * delay (current attempt is not included in totalTried, thus no need for -1)\n        const delay = retriesConfig.backoff.delay ? retriesConfig.backoff.delay : 0\n        waitUntil = new Date(getCurrentDate().getTime() + Math.pow(2, totalTried) * delay)\n      }\n    }\n  }\n\n  /*\n  const differenceInMSBetweenNowAndWaitUntil = waitUntil.getTime() - getCurrentDate().getTime()\n\n  const differenceInSBetweenNowAndWaitUntil = differenceInMSBetweenNowAndWaitUntil / 1000\n  console.log('Calculated backoff', {\n    differenceInMSBetweenNowAndWaitUntil,\n    differenceInSBetweenNowAndWaitUntil,\n    retriesConfig,\n    totalTried,\n  })*/\n  return waitUntil\n}\n"],"names":["getCurrentDate","calculateBackoffWaitUntil","retriesConfig","totalTried","waitUntil","backoff","type","delay","Date","getTime","Math","pow"],"mappings":";;;;AAEA,SAASA,cAAc,QAAQ,iCAAgC;;AAExD,SAASC,0BAA0B,EACxCC,aAAa,EACbC,UAAU,EAIX;IACC,IAAIC,gBAAkBJ,oSAAAA;IACtB,IAAI,OAAOE,kBAAkB,UAAU;QACrC,IAAIA,cAAcG,OAAO,EAAE;YACzB,IAAIH,cAAcG,OAAO,CAACC,IAAI,KAAK,SAAS;gBAC1CF,YAAYF,cAAcG,OAAO,CAACE,KAAK,GACnC,IAAIC,SAAKR,oSAAAA,IAAiBS,OAAO,KAAKP,cAAcG,OAAO,CAACE,KAAK,QACjEP,oSAAAA;YACN,OAAO,IAAIE,cAAcG,OAAO,CAACC,IAAI,KAAK,eAAe;gBACvD,kGAAkG;gBAClG,MAAMC,QAAQL,cAAcG,OAAO,CAACE,KAAK,GAAGL,cAAcG,OAAO,CAACE,KAAK,GAAG;gBAC1EH,YAAY,IAAII,SAAKR,oSAAAA,IAAiBS,OAAO,KAAKC,KAAKC,GAAG,CAAC,GAAGR,cAAcI;YAC9E;QACF;IACF;IAEA;;;;;;;;;IASE,GACF,OAAOH;AACT"}},
    {"offset": {"line": 805, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/errors/getWorkflowRetryBehavior.ts"],"sourcesContent":["import type { Job } from '../../index.js'\nimport type { RetryConfig } from '../config/types/taskTypes.js'\n\nimport { calculateBackoffWaitUntil } from './calculateBackoffWaitUntil.js'\n\n/**\n * Assuming there is no task that has already reached max retries,\n * this function determines if the workflow should retry the job\n * and if so, when it should retry.\n */\nexport function getWorkflowRetryBehavior({\n  job,\n  retriesConfig,\n}: {\n  job: Job\n  retriesConfig?: number | RetryConfig\n}):\n  | {\n      hasFinalError: false\n      maxWorkflowRetries?: number\n      waitUntil?: Date\n    }\n  | {\n      hasFinalError: true\n      maxWorkflowRetries?: number\n      waitUntil?: Date\n    } {\n  const maxWorkflowRetries = (\n    typeof retriesConfig === 'object' ? retriesConfig.attempts : retriesConfig\n  )!\n\n  if (\n    maxWorkflowRetries !== undefined &&\n    maxWorkflowRetries !== null &&\n    job.totalTried >= maxWorkflowRetries\n  ) {\n    return {\n      hasFinalError: true,\n      maxWorkflowRetries,\n    }\n  }\n\n  if (!retriesConfig) {\n    // No retries provided => assuming no task reached max retries, we can retry\n    return {\n      hasFinalError: false,\n      maxWorkflowRetries: undefined,\n      waitUntil: undefined,\n    }\n  }\n\n  // Job will retry. Let's determine when!\n  const waitUntil: Date = calculateBackoffWaitUntil({\n    retriesConfig,\n    totalTried: job.totalTried ?? 0,\n  })\n\n  return {\n    hasFinalError: false,\n    maxWorkflowRetries,\n    waitUntil,\n  }\n}\n"],"names":["calculateBackoffWaitUntil","getWorkflowRetryBehavior","job","retriesConfig","maxWorkflowRetries","attempts","undefined","totalTried","hasFinalError","waitUntil"],"mappings":";;;;AAGA,SAASA,yBAAyB,QAAQ,iCAAgC;;AAOnE,SAASC,yBAAyB,EACvCC,GAAG,EACHC,aAAa,EAId;IAWC,MAAMC,qBACJ,OAAOD,kBAAkB,WAAWA,cAAcE,QAAQ,GAAGF;IAG/D,IACEC,uBAAuBE,aACvBF,uBAAuB,QACvBF,IAAIK,UAAU,IAAIH,oBAClB;QACA,OAAO;YACLI,eAAe;YACfJ;QACF;IACF;IAEA,IAAI,CAACD,eAAe;QAClB,4EAA4E;QAC5E,OAAO;YACLK,eAAe;YACfJ,oBAAoBE;YACpBG,WAAWH;QACb;IACF;IAEA,wCAAwC;IACxC,MAAMG,gBAAkBT,uTAAAA,EAA0B;QAChDG;QACAI,YAAYL,IAAIK,UAAU,IAAI;IAChC;IAEA,OAAO;QACLC,eAAe;QACfJ;QACAK;IACF;AACF"}},
    {"offset": {"line": 842, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/errors/handleTaskError.ts"],"sourcesContent":["import ObjectIdImport from 'bson-objectid'\n\nimport type { JobLog, PayloadRequest } from '../../index.js'\nimport type { RunJobsSilent } from '../localAPI.js'\nimport type { UpdateJobFunction } from '../operations/runJobs/runJob/getUpdateJobFunction.js'\nimport type { TaskError } from './index.js'\n\nimport { getCurrentDate } from '../utilities/getCurrentDate.js'\nimport { calculateBackoffWaitUntil } from './calculateBackoffWaitUntil.js'\nimport { getWorkflowRetryBehavior } from './getWorkflowRetryBehavior.js'\n\nconst ObjectId = 'default' in ObjectIdImport ? ObjectIdImport.default : ObjectIdImport\n\nexport async function handleTaskError({\n  error,\n  req,\n  silent = false,\n  updateJob,\n}: {\n  error: TaskError\n  req: PayloadRequest\n  /**\n   * If set to true, the job system will not log any output to the console (for both info and error logs).\n   * Can be an option for more granular control over logging.\n   *\n   * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n   *\n   * @default false\n   */\n  silent?: RunJobsSilent\n  updateJob: UpdateJobFunction\n}): Promise<{\n  hasFinalError: boolean\n}> {\n  const {\n    executedAt,\n    input,\n    job,\n    output,\n    parent,\n    retriesConfig,\n    taskConfig,\n    taskID,\n    taskSlug,\n    taskStatus,\n    workflowConfig,\n  } = error.args\n\n  if (taskConfig?.onFail) {\n    await taskConfig.onFail({\n      input,\n      job,\n      req,\n      taskStatus,\n    })\n  }\n\n  const errorJSON = {\n    name: error.name,\n    cancelled: Boolean('cancelled' in error && error.cancelled),\n    message: error.message,\n    stack: error.stack,\n  }\n\n  const currentDate = getCurrentDate()\n\n  if (job.waitUntil) {\n    // Check if waitUntil is in the past\n    const waitUntil = new Date(job.waitUntil)\n    if (waitUntil < currentDate) {\n      // Outdated waitUntil, remove it\n      delete job.waitUntil\n    }\n  }\n\n  let maxRetries: number = 0\n\n  if (retriesConfig?.attempts === undefined || retriesConfig?.attempts === null) {\n    // Inherit retries from workflow config, if they are undefined and the workflow config has retries configured\n    if (workflowConfig.retries !== undefined && workflowConfig.retries !== null) {\n      maxRetries =\n        typeof workflowConfig.retries === 'object'\n          ? typeof workflowConfig.retries.attempts === 'number'\n            ? workflowConfig.retries.attempts\n            : 0\n          : workflowConfig.retries\n    } else {\n      maxRetries = 0\n    }\n  } else {\n    maxRetries = retriesConfig.attempts\n  }\n\n  const taskLogToPush: JobLog = {\n    id: new ObjectId().toHexString(),\n    completedAt: currentDate.toISOString(),\n    error: errorJSON,\n    executedAt: executedAt.toISOString(),\n    input,\n    output: output ?? {},\n    parent: req.payload.config.jobs.addParentToTaskLog ? parent : undefined,\n    state: 'failed',\n    taskID,\n    taskSlug,\n  }\n\n  if (!taskStatus?.complete && (taskStatus?.totalTried ?? 0) >= maxRetries) {\n    /**\n     * Task reached max retries => workflow will not retry\n     */\n\n    await updateJob({\n      error: errorJSON,\n      hasError: true,\n      log: {\n        $push: taskLogToPush,\n      } as any,\n      processing: false,\n      totalTried: (job.totalTried ?? 0) + 1,\n      waitUntil: job.waitUntil,\n    })\n\n    if (!silent || (typeof silent === 'object' && !silent.error)) {\n      req.payload.logger.error({\n        err: error,\n        job,\n        msg: `Error running task ${taskID}. Attempt ${job.totalTried} - max retries reached`,\n        taskSlug,\n      })\n    }\n    return {\n      hasFinalError: true,\n    }\n  }\n\n  /**\n   * Task can retry:\n   * - If workflow can retry, allow it to retry\n   * - If workflow reached max retries, do not retry and set final error\n   */\n\n  // First set task waitUntil - if the workflow waitUntil is later, it will be updated later\n  const taskWaitUntil: Date = calculateBackoffWaitUntil({\n    retriesConfig,\n    totalTried: taskStatus?.totalTried ?? 0,\n  })\n\n  // Update job's waitUntil only if this waitUntil is later than the current one\n  if (!job.waitUntil || taskWaitUntil > new Date(job.waitUntil)) {\n    job.waitUntil = taskWaitUntil.toISOString()\n  }\n\n  const { hasFinalError, maxWorkflowRetries, waitUntil } = getWorkflowRetryBehavior({\n    job,\n    retriesConfig: workflowConfig.retries,\n  })\n\n  if (!silent || (typeof silent === 'object' && !silent.error)) {\n    req.payload.logger.error({\n      err: error,\n      job,\n      msg: `Error running task ${taskID}. Attempt ${job.totalTried + 1}${maxWorkflowRetries !== undefined ? '/' + (maxWorkflowRetries + 1) : ''}`,\n      taskSlug,\n    })\n  }\n\n  // Update job's waitUntil only if this waitUntil is later than the current one\n  if (waitUntil && (!job.waitUntil || waitUntil > new Date(job.waitUntil))) {\n    job.waitUntil = waitUntil.toISOString()\n  }\n\n  // Tasks update the job if they error - but in case there is an unhandled error (e.g. in the workflow itself, not in a task)\n  // we need to ensure the job is updated to reflect the error\n  await updateJob({\n    error: hasFinalError ? errorJSON : undefined,\n    hasError: hasFinalError, // If reached max retries => final error. If hasError is true this job will not be retried\n    log: {\n      $push: taskLogToPush,\n    } as any,\n    processing: false,\n    totalTried: (job.totalTried ?? 0) + 1,\n    waitUntil: job.waitUntil,\n  })\n\n  return {\n    hasFinalError,\n  }\n}\n"],"names":["ObjectIdImport","getCurrentDate","calculateBackoffWaitUntil","getWorkflowRetryBehavior","ObjectId","default","handleTaskError","error","req","silent","updateJob","executedAt","input","job","output","parent","retriesConfig","taskConfig","taskID","taskSlug","taskStatus","workflowConfig","args","onFail","errorJSON","name","cancelled","Boolean","message","stack","currentDate","waitUntil","Date","maxRetries","attempts","undefined","retries","taskLogToPush","id","toHexString","completedAt","toISOString","payload","config","jobs","addParentToTaskLog","state","complete","totalTried","hasError","log","$push","processing","logger","err","msg","hasFinalError","taskWaitUntil","maxWorkflowRetries"],"mappings":";;;;AAAA,OAAOA,oBAAoB,gBAAe;AAO1C,SAASC,cAAc,QAAQ,iCAAgC;AAC/D,SAASC,yBAAyB,QAAQ,iCAAgC;AAC1E,SAASC,wBAAwB,QAAQ,gCAA+B;;;;;AAExE,MAAMC,WAAW,aAAaJ,sNAAAA,GAAiBA,sNAAAA,CAAeK,OAAO,GAAGL,sNAAAA;AAEjE,eAAeM,gBAAgB,EACpCC,KAAK,EACLC,GAAG,EACHC,SAAS,KAAK,EACdC,SAAS,EAcV;IAGC,MAAM,EACJC,UAAU,EACVC,KAAK,EACLC,GAAG,EACHC,MAAM,EACNC,MAAM,EACNC,aAAa,EACbC,UAAU,EACVC,MAAM,EACNC,QAAQ,EACRC,UAAU,EACVC,cAAc,EACf,GAAGd,MAAMe,IAAI;IAEd,IAAIL,YAAYM,QAAQ;QACtB,MAAMN,WAAWM,MAAM,CAAC;YACtBX;YACAC;YACAL;YACAY;QACF;IACF;IAEA,MAAMI,YAAY;QAChBC,MAAMlB,MAAMkB,IAAI;QAChBC,WAAWC,QAAQ,eAAepB,SAASA,MAAMmB,SAAS;QAC1DE,SAASrB,MAAMqB,OAAO;QACtBC,OAAOtB,MAAMsB,KAAK;IACpB;IAEA,MAAMC,kBAAc7B,oSAAAA;IAEpB,IAAIY,IAAIkB,SAAS,EAAE;QACjB,oCAAoC;QACpC,MAAMA,YAAY,IAAIC,KAAKnB,IAAIkB,SAAS;QACxC,IAAIA,YAAYD,aAAa;YAC3B,gCAAgC;YAChC,OAAOjB,IAAIkB,SAAS;QACtB;IACF;IAEA,IAAIE,aAAqB;IAEzB,IAAIjB,eAAekB,aAAaC,aAAanB,eAAekB,aAAa,MAAM;QAC7E,6GAA6G;QAC7G,IAAIb,eAAee,OAAO,KAAKD,aAAad,eAAee,OAAO,KAAK,MAAM;YAC3EH,aACE,OAAOZ,eAAee,OAAO,KAAK,WAC9B,OAAOf,eAAee,OAAO,CAACF,QAAQ,KAAK,WACzCb,eAAee,OAAO,CAACF,QAAQ,GAC/B,IACFb,eAAee,OAAO;QAC9B,OAAO;YACLH,aAAa;QACf;IACF,OAAO;QACLA,aAAajB,cAAckB,QAAQ;IACrC;IAEA,MAAMG,gBAAwB;QAC5BC,IAAI,IAAIlC,WAAWmC,WAAW;QAC9BC,aAAaV,YAAYW,WAAW;QACpClC,OAAOiB;QACPb,YAAYA,WAAW8B,WAAW;QAClC7B;QACAE,QAAQA,UAAU,CAAC;QACnBC,QAAQP,IAAIkC,OAAO,CAACC,MAAM,CAACC,IAAI,CAACC,kBAAkB,GAAG9B,SAASoB;QAC9DW,OAAO;QACP5B;QACAC;IACF;IAEA,IAAI,CAACC,YAAY2B,YAAa3B,CAAAA,YAAY4B,cAAc,CAAA,KAAMf,YAAY;QACxE;;KAEC,GAED,MAAMvB,UAAU;YACdH,OAAOiB;YACPyB,UAAU;YACVC,KAAK;gBACHC,OAAOd;YACT;YACAe,YAAY;YACZJ,YAAanC,CAAAA,IAAImC,UAAU,IAAI,CAAA,IAAK;YACpCjB,WAAWlB,IAAIkB,SAAS;QAC1B;QAEA,IAAI,CAACtB,UAAW,OAAOA,WAAW,YAAY,CAACA,OAAOF,KAAK,EAAG;YAC5DC,IAAIkC,OAAO,CAACW,MAAM,CAAC9C,KAAK,CAAC;gBACvB+C,KAAK/C;gBACLM;gBACA0C,KAAK,CAAC,mBAAmB,EAAErC,OAAO,UAAU,EAAEL,IAAImC,UAAU,CAAC,sBAAsB,CAAC;gBACpF7B;YACF;QACF;QACA,OAAO;YACLqC,eAAe;QACjB;IACF;IAEA;;;;GAIC,GAED,0FAA0F;IAC1F,MAAMC,oBAAsBvD,uTAAAA,EAA0B;QACpDc;QACAgC,YAAY5B,YAAY4B,cAAc;IACxC;IAEA,8EAA8E;IAC9E,IAAI,CAACnC,IAAIkB,SAAS,IAAI0B,gBAAgB,IAAIzB,KAAKnB,IAAIkB,SAAS,GAAG;QAC7DlB,IAAIkB,SAAS,GAAG0B,cAAchB,WAAW;IAC3C;IAEA,MAAM,EAAEe,aAAa,EAAEE,kBAAkB,EAAE3B,SAAS,EAAE,OAAG5B,qTAAAA,EAAyB;QAChFU;QACAG,eAAeK,eAAee,OAAO;IACvC;IAEA,IAAI,CAAC3B,UAAW,OAAOA,WAAW,YAAY,CAACA,OAAOF,KAAK,EAAG;QAC5DC,IAAIkC,OAAO,CAACW,MAAM,CAAC9C,KAAK,CAAC;YACvB+C,KAAK/C;YACLM;YACA0C,KAAK,CAAC,mBAAmB,EAAErC,OAAO,UAAU,EAAEL,IAAImC,UAAU,GAAG,IAAIU,uBAAuBvB,YAAY,MAAOuB,CAAAA,qBAAqB,CAAA,IAAK,IAAI;YAC3IvC;QACF;IACF;IAEA,8EAA8E;IAC9E,IAAIY,aAAc,CAAA,CAAClB,IAAIkB,SAAS,IAAIA,YAAY,IAAIC,KAAKnB,IAAIkB,SAAS,CAAA,GAAI;QACxElB,IAAIkB,SAAS,GAAGA,UAAUU,WAAW;IACvC;IAEA,4HAA4H;IAC5H,4DAA4D;IAC5D,MAAM/B,UAAU;QACdH,OAAOiD,gBAAgBhC,YAAYW;QACnCc,UAAUO;QACVN,KAAK;YACHC,OAAOd;QACT;QACAe,YAAY;QACZJ,YAAanC,CAAAA,IAAImC,UAAU,IAAI,CAAA,IAAK;QACpCjB,WAAWlB,IAAIkB,SAAS;IAC1B;IAEA,OAAO;QACLyB;IACF;AACF"}},
    {"offset": {"line": 977, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/errors/handleWorkflowError.ts"],"sourcesContent":["import type { PayloadRequest } from '../../index.js'\nimport type { RunJobsSilent } from '../localAPI.js'\nimport type { UpdateJobFunction } from '../operations/runJobs/runJob/getUpdateJobFunction.js'\nimport type { WorkflowError } from './index.js'\n\nimport { getCurrentDate } from '../utilities/getCurrentDate.js'\nimport { getWorkflowRetryBehavior } from './getWorkflowRetryBehavior.js'\n\n/**\n * This is called if a workflow catches an error. It determines if it's a final error\n * or not and handles logging.\n * A Workflow error = error that happens anywhere in between running tasks.\n *\n * This function assumes that the error is not a TaskError, but a WorkflowError. If a task errors,\n * only a TaskError should be thrown, not a WorkflowError.\n */\nexport async function handleWorkflowError({\n  error,\n  req,\n  silent = false,\n  updateJob,\n}: {\n  error: WorkflowError\n  req: PayloadRequest\n  /**\n   * If set to true, the job system will not log any output to the console (for both info and error logs).\n   * Can be an option for more granular control over logging.\n   *\n   * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n   *\n   * @default false\n   */\n  silent?: RunJobsSilent\n  updateJob: UpdateJobFunction\n}): Promise<{\n  hasFinalError: boolean\n}> {\n  const { job, workflowConfig } = error.args\n\n  const errorJSON = {\n    name: error.name,\n    cancelled: Boolean('cancelled' in error && error.cancelled),\n    message: error.message,\n    stack: error.stack,\n  }\n\n  const { hasFinalError, maxWorkflowRetries, waitUntil } = getWorkflowRetryBehavior({\n    job,\n    retriesConfig: workflowConfig.retries!,\n  })\n\n  if (!hasFinalError) {\n    if (job.waitUntil) {\n      // Check if waitUntil is in the past\n      const waitUntil = new Date(job.waitUntil)\n      if (waitUntil < getCurrentDate()) {\n        // Outdated waitUntil, remove it\n        delete job.waitUntil\n      }\n    }\n\n    // Update job's waitUntil only if this waitUntil is later than the current one\n    if (waitUntil && (!job.waitUntil || waitUntil > new Date(job.waitUntil))) {\n      job.waitUntil = waitUntil.toISOString()\n    }\n  }\n\n  const jobLabel = job.workflowSlug || `Task: ${job.taskSlug}`\n\n  if (!silent || (typeof silent === 'object' && !silent.error)) {\n    req.payload.logger.error({\n      err: error,\n      msg: `Error running job ${jobLabel} id: ${job.id} attempt ${job.totalTried + 1}${maxWorkflowRetries !== undefined ? '/' + (maxWorkflowRetries + 1) : ''}`,\n    })\n  }\n\n  // Tasks update the job if they error - but in case there is an unhandled error (e.g. in the workflow itself, not in a task)\n  // we need to ensure the job is updated to reflect the error\n  await updateJob({\n    error: errorJSON,\n    hasError: hasFinalError, // If reached max retries => final error. If hasError is true this job will not be retried\n    processing: false,\n    totalTried: (job.totalTried ?? 0) + 1,\n    waitUntil: job.waitUntil,\n  })\n\n  return {\n    hasFinalError,\n  }\n}\n"],"names":["getCurrentDate","getWorkflowRetryBehavior","handleWorkflowError","error","req","silent","updateJob","job","workflowConfig","args","errorJSON","name","cancelled","Boolean","message","stack","hasFinalError","maxWorkflowRetries","waitUntil","retriesConfig","retries","Date","toISOString","jobLabel","workflowSlug","taskSlug","payload","logger","err","msg","id","totalTried","undefined","hasError","processing"],"mappings":";;;;AAKA,SAASA,cAAc,QAAQ,iCAAgC;AAC/D,SAASC,wBAAwB,QAAQ,gCAA+B;;;AAUjE,eAAeC,oBAAoB,EACxCC,KAAK,EACLC,GAAG,EACHC,SAAS,KAAK,EACdC,SAAS,EAcV;IAGC,MAAM,EAAEC,GAAG,EAAEC,cAAc,EAAE,GAAGL,MAAMM,IAAI;IAE1C,MAAMC,YAAY;QAChBC,MAAMR,MAAMQ,IAAI;QAChBC,WAAWC,QAAQ,eAAeV,SAASA,MAAMS,SAAS;QAC1DE,SAASX,MAAMW,OAAO;QACtBC,OAAOZ,MAAMY,KAAK;IACpB;IAEA,MAAM,EAAEC,aAAa,EAAEC,kBAAkB,EAAEC,SAAS,EAAE,OAAGjB,qTAAAA,EAAyB;QAChFM;QACAY,eAAeX,eAAeY,OAAO;IACvC;IAEA,IAAI,CAACJ,eAAe;QAClB,IAAIT,IAAIW,SAAS,EAAE;YACjB,oCAAoC;YACpC,MAAMA,YAAY,IAAIG,KAAKd,IAAIW,SAAS;YACxC,IAAIA,gBAAYlB,oSAAAA,KAAkB;gBAChC,gCAAgC;gBAChC,OAAOO,IAAIW,SAAS;YACtB;QACF;QAEA,8EAA8E;QAC9E,IAAIA,aAAc,CAAA,CAACX,IAAIW,SAAS,IAAIA,YAAY,IAAIG,KAAKd,IAAIW,SAAS,CAAA,GAAI;YACxEX,IAAIW,SAAS,GAAGA,UAAUI,WAAW;QACvC;IACF;IAEA,MAAMC,WAAWhB,IAAIiB,YAAY,IAAI,CAAC,MAAM,EAAEjB,IAAIkB,QAAQ,EAAE;IAE5D,IAAI,CAACpB,UAAW,OAAOA,WAAW,YAAY,CAACA,OAAOF,KAAK,EAAG;QAC5DC,IAAIsB,OAAO,CAACC,MAAM,CAACxB,KAAK,CAAC;YACvByB,KAAKzB;YACL0B,KAAK,CAAC,kBAAkB,EAAEN,SAAS,KAAK,EAAEhB,IAAIuB,EAAE,CAAC,SAAS,EAAEvB,IAAIwB,UAAU,GAAG,IAAId,uBAAuBe,YAAY,MAAOf,CAAAA,qBAAqB,CAAA,IAAK,IAAI;QAC3J;IACF;IAEA,4HAA4H;IAC5H,4DAA4D;IAC5D,MAAMX,UAAU;QACdH,OAAOO;QACPuB,UAAUjB;QACVkB,YAAY;QACZH,YAAaxB,CAAAA,IAAIwB,UAAU,IAAI,CAAA,IAAK;QACpCb,WAAWX,IAAIW,SAAS;IAC1B;IAEA,OAAO;QACLF;IACF;AACF"}},
    {"offset": {"line": 1035, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/runJobs/runJob/getRunTaskFunction.ts"],"sourcesContent":["import ObjectIdImport from 'bson-objectid'\n\nimport type { Job } from '../../../../index.js'\nimport type { JsonObject, PayloadRequest } from '../../../../types/index.js'\nimport type {\n  RetryConfig,\n  RunInlineTaskFunction,\n  RunTaskFunction,\n  RunTaskFunctions,\n  TaskConfig,\n  TaskHandler,\n  TaskHandlerResult,\n  TaskType,\n} from '../../../config/types/taskTypes.js'\nimport type {\n  JobLog,\n  SingleTaskStatus,\n  WorkflowConfig,\n  WorkflowTypes,\n} from '../../../config/types/workflowTypes.js'\nimport type { UpdateJobFunction } from './getUpdateJobFunction.js'\n\nimport { TaskError } from '../../../errors/index.js'\nimport { getCurrentDate } from '../../../utilities/getCurrentDate.js'\nimport { getTaskHandlerFromConfig } from './importHandlerPath.js'\n\nconst ObjectId = 'default' in ObjectIdImport ? ObjectIdImport.default : ObjectIdImport\n\nexport type TaskParent = {\n  taskID: string\n  taskSlug: string\n}\n\nexport const getRunTaskFunction = <TIsInline extends boolean>(\n  job: Job,\n  workflowConfig: WorkflowConfig,\n  req: PayloadRequest,\n  isInline: TIsInline,\n  updateJob: UpdateJobFunction,\n  parent?: TaskParent,\n): TIsInline extends true ? RunInlineTaskFunction : RunTaskFunctions => {\n  const jobConfig = req.payload.config.jobs\n\n  const runTask: <TTaskSlug extends string>(\n    taskSlug: TTaskSlug,\n  ) => TTaskSlug extends 'inline' ? RunInlineTaskFunction : RunTaskFunction<TTaskSlug> = (\n    taskSlug,\n  ) =>\n    (async (\n      taskID: Parameters<RunInlineTaskFunction>[0],\n      {\n        input,\n        retries,\n        // Only available for inline tasks:\n        task,\n      }: Parameters<RunInlineTaskFunction>[1] & Parameters<RunTaskFunction<string>>[1],\n    ) => {\n      const executedAt = getCurrentDate()\n\n      let taskConfig: TaskConfig | undefined\n      if (!isInline) {\n        taskConfig = (jobConfig.tasks?.length &&\n          jobConfig.tasks.find((t) => t.slug === taskSlug)) as TaskConfig<string>\n\n        if (!taskConfig) {\n          throw new Error(`Task ${taskSlug} not found in workflow ${job.workflowSlug}`)\n        }\n      }\n\n      const retriesConfigFromPropsNormalized =\n        retries == undefined || retries == null\n          ? {}\n          : typeof retries === 'number'\n            ? { attempts: retries }\n            : retries\n      const retriesConfigFromTaskConfigNormalized = taskConfig\n        ? typeof taskConfig.retries === 'number'\n          ? { attempts: taskConfig.retries }\n          : taskConfig.retries\n        : {}\n\n      const finalRetriesConfig: RetryConfig = {\n        ...retriesConfigFromTaskConfigNormalized,\n        ...retriesConfigFromPropsNormalized, // Retry config from props takes precedence\n      }\n\n      const taskStatus: null | SingleTaskStatus<string> = job?.taskStatus?.[taskSlug]\n        ? job.taskStatus[taskSlug][taskID]!\n        : null\n\n      // Handle restoration of task if it succeeded in a previous run\n      if (taskStatus && taskStatus.complete === true) {\n        let shouldRestore = true\n        if (finalRetriesConfig?.shouldRestore === false) {\n          shouldRestore = false\n        } else if (typeof finalRetriesConfig?.shouldRestore === 'function') {\n          shouldRestore = await finalRetriesConfig.shouldRestore({\n            input,\n            job,\n            req,\n            taskStatus,\n          })\n        }\n        if (shouldRestore) {\n          return taskStatus.output\n        }\n      }\n\n      const runner = isInline\n        ? (task as TaskHandler<TaskType>)\n        : await getTaskHandlerFromConfig(taskConfig)\n\n      if (!runner || typeof runner !== 'function') {\n        throw new TaskError({\n          executedAt,\n          input,\n          job,\n          message: isInline\n            ? `Inline task with ID ${taskID} does not have a valid handler.`\n            : `Task with slug ${taskSlug} in workflow ${job.workflowSlug} does not have a valid handler.`,\n          parent,\n          retriesConfig: finalRetriesConfig,\n          taskConfig,\n          taskID,\n          taskSlug,\n          taskStatus,\n          workflowConfig,\n        })\n      }\n\n      let taskHandlerResult: TaskHandlerResult<string>\n      let output: JsonObject | undefined = {}\n\n      try {\n        taskHandlerResult = await runner({\n          inlineTask: getRunTaskFunction(job, workflowConfig, req, true, updateJob, {\n            taskID,\n            taskSlug,\n          }),\n          input,\n          job: job as unknown as Job<WorkflowTypes>,\n          req,\n          tasks: getRunTaskFunction(job, workflowConfig, req, false, updateJob, {\n            taskID,\n            taskSlug,\n          }),\n        })\n      } catch (err: any) {\n        throw new TaskError({\n          executedAt,\n          input: input!,\n          job,\n          message: err.message || 'Task handler threw an error',\n          output,\n          parent,\n          retriesConfig: finalRetriesConfig,\n          taskConfig,\n          taskID,\n          taskSlug,\n          taskStatus,\n          workflowConfig,\n        })\n      }\n\n      if (taskHandlerResult.state === 'failed') {\n        throw new TaskError({\n          executedAt,\n          input: input!,\n          job,\n          message: taskHandlerResult.errorMessage ?? 'Task handler returned a failed state',\n          output,\n          parent,\n          retriesConfig: finalRetriesConfig,\n          taskConfig,\n          taskID,\n          taskSlug,\n          taskStatus,\n          workflowConfig,\n        })\n      } else {\n        output = taskHandlerResult.output\n      }\n\n      if (taskConfig?.onSuccess) {\n        await taskConfig.onSuccess({\n          input,\n          job,\n          req,\n          taskStatus,\n        })\n      }\n\n      const newLogItem: JobLog = {\n        id: new ObjectId().toHexString(),\n        completedAt: getCurrentDate().toISOString(),\n        executedAt: executedAt.toISOString(),\n        input,\n        output,\n        parent: jobConfig.addParentToTaskLog ? parent : undefined,\n        state: 'succeeded',\n        taskID,\n        taskSlug,\n      }\n\n      await updateJob({\n        log: {\n          $push: newLogItem,\n        } as any,\n        // Set to null to skip main row update on postgres. 2 => 1 db round trips\n        updatedAt: null as any,\n      })\n\n      return output\n    }) as any\n\n  if (isInline) {\n    return runTask('inline') as TIsInline extends true ? RunInlineTaskFunction : RunTaskFunctions\n  } else {\n    const tasks: RunTaskFunctions = {}\n    for (const task of jobConfig.tasks ?? []) {\n      tasks[task.slug] = runTask(task.slug) as RunTaskFunction<string>\n    }\n    return tasks as TIsInline extends true ? RunInlineTaskFunction : RunTaskFunctions\n  }\n}\n"],"names":["ObjectIdImport","TaskError","getCurrentDate","getTaskHandlerFromConfig","ObjectId","default","getRunTaskFunction","job","workflowConfig","req","isInline","updateJob","parent","jobConfig","payload","config","jobs","runTask","taskSlug","taskID","input","retries","task","executedAt","taskConfig","tasks","length","find","t","slug","Error","workflowSlug","retriesConfigFromPropsNormalized","undefined","attempts","retriesConfigFromTaskConfigNormalized","finalRetriesConfig","taskStatus","complete","shouldRestore","output","runner","message","retriesConfig","taskHandlerResult","inlineTask","err","state","errorMessage","onSuccess","newLogItem","id","toHexString","completedAt","toISOString","addParentToTaskLog","log","$push","updatedAt"],"mappings":";;;;AAAA,OAAOA,oBAAoB,gBAAe;AAsB1C,SAASC,SAAS,QAAQ,2BAA0B;AACpD,SAASC,cAAc,QAAQ,uCAAsC;AACrE,SAASC,wBAAwB,QAAQ,yBAAwB;;;;;AAEjE,MAAMC,WAAW,aAAaJ,sNAAAA,GAAiBA,sNAAAA,CAAeK,OAAO,GAAGL,sNAAAA;AAOjE,MAAMM,qBAAqB,CAChCC,KACAC,gBACAC,KACAC,UACAC,WACAC;IAEA,MAAMC,YAAYJ,IAAIK,OAAO,CAACC,MAAM,CAACC,IAAI;IAEzC,MAAMC,UAEiF,CACrFC,WAEC,OACCC,QACA,EACEC,KAAK,EACLC,OAAO,EACP,AACAC,IAAI,EAC0E,6BAF3C;YAIrC,MAAMC,iBAAarB,oSAAAA;YAEnB,IAAIsB;YACJ,IAAI,CAACd,UAAU;gBACbc,aAAcX,UAAUY,KAAK,EAAEC,UAC7Bb,UAAUY,KAAK,CAACE,IAAI,CAAC,CAACC,IAAMA,EAAEC,IAAI,KAAKX;gBAEzC,IAAI,CAACM,YAAY;oBACf,MAAM,IAAIM,MAAM,CAAC,KAAK,EAAEZ,SAAS,uBAAuB,EAAEX,IAAIwB,YAAY,EAAE;gBAC9E;YACF;YAEA,MAAMC,mCACJX,WAAWY,aAAaZ,WAAW,OAC/B,CAAC,IACD,OAAOA,YAAY,WACjB;gBAAEa,UAAUb;YAAQ,IACpBA;YACR,MAAMc,wCAAwCX,aAC1C,OAAOA,WAAWH,OAAO,KAAK,WAC5B;gBAAEa,UAAUV,WAAWH,OAAO;YAAC,IAC/BG,WAAWH,OAAO,GACpB,CAAC;YAEL,MAAMe,qBAAkC;gBACtC,GAAGD,qCAAqC;gBACxC,GAAGH,gCAAgC;YACrC;YAEA,MAAMK,aAA8C9B,KAAK8B,YAAY,CAACnB,SAAS,GAC3EX,IAAI8B,UAAU,CAACnB,SAAS,CAACC,OAAO,GAChC;YAEJ,+DAA+D;YAC/D,IAAIkB,cAAcA,WAAWC,QAAQ,KAAK,MAAM;gBAC9C,IAAIC,gBAAgB;gBACpB,IAAIH,oBAAoBG,kBAAkB,OAAO;oBAC/CA,gBAAgB;gBAClB,OAAO,IAAI,OAAOH,oBAAoBG,kBAAkB,YAAY;oBAClEA,gBAAgB,MAAMH,mBAAmBG,aAAa,CAAC;wBACrDnB;wBACAb;wBACAE;wBACA4B;oBACF;gBACF;gBACA,IAAIE,eAAe;oBACjB,OAAOF,WAAWG,MAAM;gBAC1B;YACF;YAEA,MAAMC,SAAS/B,WACVY,OACD,UAAMnB,uUAAAA,EAAyBqB;YAEnC,IAAI,CAACiB,UAAU,OAAOA,WAAW,YAAY;gBAC3C,MAAM,IAAIxC,mRAAAA,CAAU;oBAClBsB;oBACAH;oBACAb;oBACAmC,SAAShC,WACL,CAAC,oBAAoB,EAAES,OAAO,+BAA+B,CAAC,GAC9D,CAAC,eAAe,EAAED,SAAS,aAAa,EAAEX,IAAIwB,YAAY,CAAC,+BAA+B,CAAC;oBAC/FnB;oBACA+B,eAAeP;oBACfZ;oBACAL;oBACAD;oBACAmB;oBACA7B;gBACF;YACF;YAEA,IAAIoC;YACJ,IAAIJ,SAAiC,CAAC;YAEtC,IAAI;gBACFI,oBAAoB,MAAMH,OAAO;oBAC/BI,YAAYvC,mBAAmBC,KAAKC,gBAAgBC,KAAK,MAAME,WAAW;wBACxEQ;wBACAD;oBACF;oBACAE;oBACAb,KAAKA;oBACLE;oBACAgB,OAAOnB,mBAAmBC,KAAKC,gBAAgBC,KAAK,OAAOE,WAAW;wBACpEQ;wBACAD;oBACF;gBACF;YACF,EAAE,OAAO4B,KAAU;gBACjB,MAAM,IAAI7C,mRAAAA,CAAU;oBAClBsB;oBACAH,OAAOA;oBACPb;oBACAmC,SAASI,IAAIJ,OAAO,IAAI;oBACxBF;oBACA5B;oBACA+B,eAAeP;oBACfZ;oBACAL;oBACAD;oBACAmB;oBACA7B;gBACF;YACF;YAEA,IAAIoC,kBAAkBG,KAAK,KAAK,UAAU;gBACxC,MAAM,IAAI9C,mRAAAA,CAAU;oBAClBsB;oBACAH,OAAOA;oBACPb;oBACAmC,SAASE,kBAAkBI,YAAY,IAAI;oBAC3CR;oBACA5B;oBACA+B,eAAeP;oBACfZ;oBACAL;oBACAD;oBACAmB;oBACA7B;gBACF;YACF,OAAO;gBACLgC,SAASI,kBAAkBJ,MAAM;YACnC;YAEA,IAAIhB,YAAYyB,WAAW;gBACzB,MAAMzB,WAAWyB,SAAS,CAAC;oBACzB7B;oBACAb;oBACAE;oBACA4B;gBACF;YACF;YAEA,MAAMa,aAAqB;gBACzBC,IAAI,IAAI/C,WAAWgD,WAAW;gBAC9BC,iBAAanD,oSAAAA,IAAiBoD,WAAW;gBACzC/B,YAAYA,WAAW+B,WAAW;gBAClClC;gBACAoB;gBACA5B,QAAQC,UAAU0C,kBAAkB,GAAG3C,SAASqB;gBAChDc,OAAO;gBACP5B;gBACAD;YACF;YAEA,MAAMP,UAAU;gBACd6C,KAAK;oBACHC,OAAOP;gBACT;gBACA,yEAAyE;gBACzEQ,WAAW;YACb;YAEA,OAAOlB;QACT;IAEF,IAAI9B,UAAU;QACZ,OAAOO,QAAQ;IACjB,OAAO;QACL,MAAMQ,QAA0B,CAAC;QACjC,KAAK,MAAMH,QAAQT,UAAUY,KAAK,IAAI,EAAE,CAAE;YACxCA,KAAK,CAACH,KAAKO,IAAI,CAAC,GAAGZ,QAAQK,KAAKO,IAAI;QACtC;QACA,OAAOJ;IACT;AACF,EAAC"}},
    {"offset": {"line": 1195, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/runJobs/runJob/index.ts"],"sourcesContent":["import type { Job } from '../../../../index.js'\nimport type { PayloadRequest } from '../../../../types/index.js'\nimport type { WorkflowConfig, WorkflowHandler } from '../../../config/types/workflowTypes.js'\nimport type { RunJobsSilent } from '../../../localAPI.js'\nimport type { UpdateJobFunction } from './getUpdateJobFunction.js'\n\nimport { handleTaskError } from '../../../errors/handleTaskError.js'\nimport { handleWorkflowError } from '../../../errors/handleWorkflowError.js'\nimport { JobCancelledError, TaskError, WorkflowError } from '../../../errors/index.js'\nimport { getCurrentDate } from '../../../utilities/getCurrentDate.js'\nimport { getRunTaskFunction } from './getRunTaskFunction.js'\n\ntype Args = {\n  job: Job\n  req: PayloadRequest\n  /**\n   * If set to true, the job system will not log any output to the console (for both info and error logs).\n   * Can be an option for more granular control over logging.\n   *\n   * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n   *\n   * @default false\n   */\n  silent?: RunJobsSilent\n  updateJob: UpdateJobFunction\n  workflowConfig: WorkflowConfig\n  workflowHandler: WorkflowHandler\n}\n\nexport type JobRunStatus = 'error' | 'error-reached-max-retries' | 'success'\n\nexport type RunJobResult = {\n  status: JobRunStatus\n}\n\nexport const runJob = async ({\n  job,\n  req,\n  silent,\n  updateJob,\n  workflowConfig,\n  workflowHandler,\n}: Args): Promise<RunJobResult> => {\n  // Run the job\n  try {\n    await workflowHandler({\n      inlineTask: getRunTaskFunction(job, workflowConfig, req, true, updateJob),\n      job,\n      req,\n      tasks: getRunTaskFunction(job, workflowConfig, req, false, updateJob),\n    })\n  } catch (error) {\n    if (error instanceof JobCancelledError) {\n      throw error // Job cancellation is handled in a top-level error handler, as higher up code may themselves throw this error\n    }\n    if (error instanceof TaskError) {\n      const { hasFinalError } = await handleTaskError({\n        error,\n        req,\n        silent,\n        updateJob,\n      })\n\n      return {\n        status: hasFinalError ? 'error-reached-max-retries' : 'error',\n      }\n    }\n\n    const { hasFinalError } = await handleWorkflowError({\n      error:\n        error instanceof WorkflowError\n          ? error\n          : new WorkflowError({\n              job,\n              message:\n                typeof error === 'object' && error && 'message' in error\n                  ? (error.message as string)\n                  : 'An unhandled error occurred',\n              workflowConfig,\n            }),\n      req,\n      silent,\n      updateJob,\n    })\n\n    return {\n      status: hasFinalError ? 'error-reached-max-retries' : 'error',\n    }\n  }\n\n  // Workflow has completed successfully\n  // Do not update the job log here, as that would result in unnecessary db calls when using postgres.\n  // Solely updating simple fields here will result in optimized db calls.\n  // Job log modifications are already updated at the end of the runTask function.\n  await updateJob({\n    completedAt: getCurrentDate().toISOString(),\n    processing: false,\n    totalTried: (job.totalTried ?? 0) + 1,\n  })\n\n  return {\n    status: 'success',\n  }\n}\n"],"names":["handleTaskError","handleWorkflowError","JobCancelledError","TaskError","WorkflowError","getCurrentDate","getRunTaskFunction","runJob","job","req","silent","updateJob","workflowConfig","workflowHandler","inlineTask","tasks","error","hasFinalError","status","message","completedAt","toISOString","processing","totalTried"],"mappings":";;;;AAMA,SAASA,eAAe,QAAQ,qCAAoC;AACpE,SAASC,mBAAmB,QAAQ,yCAAwC;AAC5E,SAASC,iBAAiB,EAAEC,SAAS,EAAEC,aAAa,QAAQ,2BAA0B;AACtF,SAASC,cAAc,QAAQ,uCAAsC;AACrE,SAASC,kBAAkB,QAAQ,0BAAyB;;;;;;AAyBrD,MAAMC,SAAS,OAAO,EAC3BC,GAAG,EACHC,GAAG,EACHC,MAAM,EACNC,SAAS,EACTC,cAAc,EACdC,eAAe,EACV;IACL,cAAc;IACd,IAAI;QACF,MAAMA,gBAAgB;YACpBC,gBAAYR,kUAAAA,EAAmBE,KAAKI,gBAAgBH,KAAK,MAAME;YAC/DH;YACAC;YACAM,WAAOT,kUAAAA,EAAmBE,KAAKI,gBAAgBH,KAAK,OAAOE;QAC7D;IACF,EAAE,OAAOK,OAAO;QACd,IAAIA,iBAAiBd,2RAAAA,EAAmB;YACtC,MAAMc,MAAM,8GAA8G;;QAC5H;QACA,IAAIA,iBAAiBb,mRAAAA,EAAW;YAC9B,MAAM,EAAEc,aAAa,EAAE,GAAG,UAAMjB,mSAAAA,EAAgB;gBAC9CgB;gBACAP;gBACAC;gBACAC;YACF;YAEA,OAAO;gBACLO,QAAQD,gBAAgB,8BAA8B;YACxD;QACF;QAEA,MAAM,EAAEA,aAAa,EAAE,GAAG,UAAMhB,2SAAAA,EAAoB;YAClDe,OACEA,iBAAiBZ,uRAAAA,GACbY,QACA,IAAIZ,uRAAAA,CAAc;gBAChBI;gBACAW,SACE,OAAOH,UAAU,YAAYA,SAAS,aAAaA,QAC9CA,MAAMG,OAAO,GACd;gBACNP;YACF;YACNH;YACAC;YACAC;QACF;QAEA,OAAO;YACLO,QAAQD,gBAAgB,8BAA8B;QACxD;IACF;IAEA,sCAAsC;IACtC,oGAAoG;IACpG,wEAAwE;IACxE,gFAAgF;IAChF,MAAMN,UAAU;QACdS,iBAAaf,oSAAAA,IAAiBgB,WAAW;QACzCC,YAAY;QACZC,YAAaf,CAAAA,IAAIe,UAAU,IAAI,CAAA,IAAK;IACtC;IAEA,OAAO;QACLL,QAAQ;IACV;AACF,EAAC"}},
    {"offset": {"line": 1265, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/runJobs/runJSONJob/index.ts"],"sourcesContent":["import type { Job } from '../../../../index.js'\nimport type { PayloadRequest } from '../../../../types/index.js'\nimport type { WorkflowJSON, WorkflowStep } from '../../../config/types/workflowJSONTypes.js'\nimport type { WorkflowConfig } from '../../../config/types/workflowTypes.js'\nimport type { RunJobsSilent } from '../../../localAPI.js'\nimport type { UpdateJobFunction } from '../runJob/getUpdateJobFunction.js'\nimport type { JobRunStatus } from '../runJob/index.js'\n\nimport { handleWorkflowError } from '../../../errors/handleWorkflowError.js'\nimport { WorkflowError } from '../../../errors/index.js'\nimport { getCurrentDate } from '../../../utilities/getCurrentDate.js'\nimport { getRunTaskFunction } from '../runJob/getRunTaskFunction.js'\n\ntype Args = {\n  job: Job\n  req: PayloadRequest\n  /**\n   * If set to true, the job system will not log any output to the console (for both info and error logs).\n   * Can be an option for more granular control over logging.\n   *\n   * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n   *\n   * @default false\n   */\n  silent?: RunJobsSilent\n  updateJob: UpdateJobFunction\n  workflowConfig: WorkflowConfig\n  workflowHandler: WorkflowJSON\n}\n\nexport type RunJSONJobResult = {\n  status: JobRunStatus\n}\n\nexport const runJSONJob = async ({\n  job,\n  req,\n  silent = false,\n  updateJob,\n  workflowConfig,\n  workflowHandler,\n}: Args): Promise<RunJSONJobResult> => {\n  const stepsToRun: WorkflowStep<string>[] = []\n\n  for (const step of workflowHandler) {\n    if ('task' in step) {\n      if (job?.taskStatus?.[step.task]?.[step.id]?.complete) {\n        continue\n      }\n    } else {\n      if (job?.taskStatus?.['inline']?.[step.id]?.complete) {\n        continue\n      }\n    }\n    if (step.condition && !step.condition({ job })) {\n      continue\n    }\n    stepsToRun.push(step)\n  }\n\n  const tasks = getRunTaskFunction(job, workflowConfig, req, false, updateJob)\n  const inlineTask = getRunTaskFunction(job, workflowConfig, req, true, updateJob)\n\n  // Run the job\n  try {\n    await Promise.all(\n      stepsToRun.map(async (step) => {\n        if ('task' in step) {\n          await tasks[step.task]!(step.id, {\n            input: step.input ? step.input({ job }) : {},\n            retries: step.retries,\n          })\n        } else {\n          await inlineTask(step.id, {\n            retries: step.retries,\n            task: step.inlineTask as any, // TODO: Fix type\n          })\n        }\n      }),\n    )\n  } catch (error) {\n    const { hasFinalError } = await handleWorkflowError({\n      error:\n        error instanceof WorkflowError\n          ? error\n          : new WorkflowError({\n              job,\n              message:\n                typeof error === 'object' && error && 'message' in error\n                  ? (error.message as string)\n                  : 'An unhandled error occurred',\n              workflowConfig,\n            }),\n      silent,\n\n      req,\n      updateJob,\n    })\n\n    return {\n      status: hasFinalError ? 'error-reached-max-retries' : 'error',\n    }\n  }\n\n  // Check if workflow has completed\n  let workflowCompleted = false\n  for (const [slug, map] of Object.entries(job.taskStatus)) {\n    for (const [id, taskStatus] of Object.entries(map)) {\n      if (taskStatus.complete) {\n        const step = workflowHandler.find((step) => {\n          if ('task' in step) {\n            return step.task === slug && step.id === id\n          } else {\n            return step.id === id && slug === 'inline'\n          }\n        })\n        if (step?.completesJob) {\n          workflowCompleted = true\n          break\n        }\n      }\n    }\n  }\n\n  if (workflowCompleted) {\n    await updateJob({\n      completedAt: getCurrentDate().toISOString(),\n      processing: false,\n      totalTried: (job.totalTried ?? 0) + 1,\n    })\n\n    return {\n      status: 'success',\n    }\n  } else {\n    // Retry the job - no need to bump processing or totalTried as this does not count as a retry. A condition of a different task might have just opened up!\n    return await runJSONJob({\n      job,\n      req,\n      updateJob,\n      workflowConfig,\n      workflowHandler,\n    })\n  }\n}\n"],"names":["handleWorkflowError","WorkflowError","getCurrentDate","getRunTaskFunction","runJSONJob","job","req","silent","updateJob","workflowConfig","workflowHandler","stepsToRun","step","taskStatus","task","id","complete","condition","push","tasks","inlineTask","Promise","all","map","input","retries","error","hasFinalError","message","status","workflowCompleted","slug","Object","entries","find","completesJob","completedAt","toISOString","processing","totalTried"],"mappings":";;;;AAQA,SAASA,mBAAmB,QAAQ,yCAAwC;AAC5E,SAASC,aAAa,QAAQ,2BAA0B;AACxD,SAASC,cAAc,QAAQ,uCAAsC;AACrE,SAASC,kBAAkB,QAAQ,kCAAiC;;;;;AAuB7D,MAAMC,aAAa,OAAO,EAC/BC,GAAG,EACHC,GAAG,EACHC,SAAS,KAAK,EACdC,SAAS,EACTC,cAAc,EACdC,eAAe,EACV;IACL,MAAMC,aAAqC,EAAE;IAE7C,KAAK,MAAMC,QAAQF,gBAAiB;QAClC,IAAI,UAAUE,MAAM;YAClB,IAAIP,KAAKQ,YAAY,CAACD,KAAKE,IAAI,CAAC,EAAE,CAACF,KAAKG,EAAE,CAAC,EAAEC,UAAU;gBACrD;YACF;QACF,OAAO;YACL,IAAIX,KAAKQ,YAAY,CAAC,SAAS,EAAE,CAACD,KAAKG,EAAE,CAAC,EAAEC,UAAU;gBACpD;YACF;QACF;QACA,IAAIJ,KAAKK,SAAS,IAAI,CAACL,KAAKK,SAAS,CAAC;YAAEZ;QAAI,IAAI;YAC9C;QACF;QACAM,WAAWO,IAAI,CAACN;IAClB;IAEA,MAAMO,YAAQhB,kUAAAA,EAAmBE,KAAKI,gBAAgBH,KAAK,OAAOE;IAClE,MAAMY,iBAAajB,kUAAAA,EAAmBE,KAAKI,gBAAgBH,KAAK,MAAME;IAEtE,cAAc;IACd,IAAI;QACF,MAAMa,QAAQC,GAAG,CACfX,WAAWY,GAAG,CAAC,OAAOX;YACpB,IAAI,UAAUA,MAAM;gBAClB,MAAMO,KAAK,CAACP,KAAKE,IAAI,CAAC,CAAEF,KAAKG,EAAE,EAAE;oBAC/BS,OAAOZ,KAAKY,KAAK,GAAGZ,KAAKY,KAAK,CAAC;wBAAEnB;oBAAI,KAAK,CAAC;oBAC3CoB,SAASb,KAAKa,OAAO;gBACvB;YACF,OAAO;gBACL,MAAML,WAAWR,KAAKG,EAAE,EAAE;oBACxBU,SAASb,KAAKa,OAAO;oBACrBX,MAAMF,KAAKQ,UAAU;gBACvB;YACF;QACF;IAEJ,EAAE,OAAOM,OAAO;QACd,MAAM,EAAEC,aAAa,EAAE,GAAG,UAAM3B,2SAAAA,EAAoB;YAClD0B,OACEA,iBAAiBzB,uRAAAA,GACbyB,QACA,IAAIzB,uRAAAA,CAAc;gBAChBI;gBACAuB,SACE,OAAOF,UAAU,YAAYA,SAAS,aAAaA,QAC9CA,MAAME,OAAO,GACd;gBACNnB;YACF;YACNF;YAEAD;YACAE;QACF;QAEA,OAAO;YACLqB,QAAQF,gBAAgB,8BAA8B;QACxD;IACF;IAEA,kCAAkC;IAClC,IAAIG,oBAAoB;IACxB,KAAK,MAAM,CAACC,MAAMR,IAAI,IAAIS,OAAOC,OAAO,CAAC5B,IAAIQ,UAAU,EAAG;QACxD,KAAK,MAAM,CAACE,IAAIF,WAAW,IAAImB,OAAOC,OAAO,CAACV,KAAM;YAClD,IAAIV,WAAWG,QAAQ,EAAE;gBACvB,MAAMJ,OAAOF,gBAAgBwB,IAAI,CAAC,CAACtB;oBACjC,IAAI,UAAUA,MAAM;wBAClB,OAAOA,KAAKE,IAAI,KAAKiB,QAAQnB,KAAKG,EAAE,KAAKA;oBAC3C,OAAO;wBACL,OAAOH,KAAKG,EAAE,KAAKA,MAAMgB,SAAS;oBACpC;gBACF;gBACA,IAAInB,MAAMuB,cAAc;oBACtBL,oBAAoB;oBACpB;gBACF;YACF;QACF;IACF;IAEA,IAAIA,mBAAmB;QACrB,MAAMtB,UAAU;YACd4B,iBAAalC,oSAAAA,IAAiBmC,WAAW;YACzCC,YAAY;YACZC,YAAalC,CAAAA,IAAIkC,UAAU,IAAI,CAAA,IAAK;QACtC;QAEA,OAAO;YACLV,QAAQ;QACV;IACF,OAAO;QACL,yJAAyJ;QACzJ,OAAO,MAAMzB,WAAW;YACtBC;YACAC;YACAE;YACAC;YACAC;QACF;IACF;AACF,EAAC"}},
    {"offset": {"line": 1373, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/operations/runJobs/index.ts"],"sourcesContent":["import type { Job } from '../../../index.js'\nimport type { PayloadRequest, Sort, Where } from '../../../types/index.js'\nimport type { WorkflowJSON } from '../../config/types/workflowJSONTypes.js'\nimport type { WorkflowConfig, WorkflowHandler } from '../../config/types/workflowTypes.js'\nimport type { RunJobsSilent } from '../../localAPI.js'\nimport type { RunJobResult } from './runJob/index.js'\n\nimport { Forbidden } from '../../../errors/Forbidden.js'\nimport { isolateObjectProperty } from '../../../utilities/isolateObjectProperty.js'\nimport { jobsCollectionSlug } from '../../config/collection.js'\nimport { JobCancelledError } from '../../errors/index.js'\nimport { getCurrentDate } from '../../utilities/getCurrentDate.js'\nimport { updateJob, updateJobs } from '../../utilities/updateJob.js'\nimport { getUpdateJobFunction } from './runJob/getUpdateJobFunction.js'\nimport { importHandlerPath } from './runJob/importHandlerPath.js'\nimport { runJob } from './runJob/index.js'\nimport { runJSONJob } from './runJSONJob/index.js'\n\nexport type RunJobsArgs = {\n  /**\n   * If you want to run jobs from all queues, set this to true.\n   * If you set this to true, the `queue` property will be ignored.\n   *\n   * @default false\n   */\n  allQueues?: boolean\n  /**\n   * ID of the job to run\n   */\n  id?: number | string\n  /**\n   * The maximum number of jobs to run in this invocation\n   *\n   * @default 10\n   */\n  limit?: number\n  overrideAccess?: boolean\n  /**\n   * Adjust the job processing order\n   *\n   * FIFO would equal `createdAt` and LIFO would equal `-createdAt`.\n   *\n   * @default all jobs for all queues will be executed in FIFO order.\n   */\n  processingOrder?: Sort\n  /**\n   * If you want to run jobs from a specific queue, set this to the queue name.\n   *\n   * @default jobs from the `default` queue will be executed.\n   */\n  queue?: string\n  req: PayloadRequest\n  /**\n   * By default, jobs are run in parallel.\n   * If you want to run them in sequence, set this to true.\n   */\n  sequential?: boolean\n  /**\n   * If set to true, the job system will not log any output to the console (for both info and error logs).\n   * Can be an option for more granular control over logging.\n   *\n   * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n   *\n   * @default false\n   */\n  silent?: RunJobsSilent\n  where?: Where\n}\n\nexport type RunJobsResult = {\n  jobStatus?: Record<string, RunJobResult>\n  /**\n   * If this is false, there for sure are no jobs remaining, regardless of the limit\n   */\n  noJobsRemaining?: boolean\n  /**\n   * Out of the jobs that were queried & processed (within the set limit), how many are remaining and retryable?\n   */\n  remainingJobsFromQueried: number\n}\n\nexport const runJobs = async (args: RunJobsArgs): Promise<RunJobsResult> => {\n  const {\n    id,\n    allQueues = false,\n    limit = 10,\n    overrideAccess,\n    processingOrder,\n    queue = 'default',\n    req,\n    req: {\n      payload,\n      payload: {\n        config: { jobs: jobsConfig },\n      },\n    },\n    sequential,\n    silent = false,\n    where: whereFromProps,\n  } = args\n\n  if (!overrideAccess) {\n    /**\n     * By default, jobsConfig.access.run will be `defaultAccess` which is a function that returns `true` if the user is logged in.\n     */\n    const accessFn = jobsConfig?.access?.run ?? (() => true)\n    const hasAccess = await accessFn({ req })\n    if (!hasAccess) {\n      throw new Forbidden(req.t)\n    }\n  }\n  const and: Where[] = [\n    {\n      completedAt: {\n        exists: false,\n      },\n    },\n    {\n      hasError: {\n        not_equals: true,\n      },\n    },\n    {\n      processing: {\n        equals: false,\n      },\n    },\n    {\n      or: [\n        {\n          waitUntil: {\n            exists: false,\n          },\n        },\n        {\n          waitUntil: {\n            less_than: getCurrentDate().toISOString(),\n          },\n        },\n      ],\n    },\n  ]\n\n  if (allQueues !== true) {\n    and.push({\n      queue: {\n        equals: queue ?? 'default',\n      },\n    })\n  }\n\n  if (whereFromProps) {\n    and.push(whereFromProps)\n  }\n\n  // Find all jobs and ensure we set job to processing: true as early as possible to reduce the chance of\n  // the same job being picked up by another worker\n  let jobs: Job[] = []\n\n  if (id) {\n    // Only one job to run\n    const job = await updateJob({\n      id,\n      data: {\n        processing: true,\n      },\n      depth: jobsConfig.depth,\n      disableTransaction: true,\n      req,\n      returning: true,\n    })\n    if (job) {\n      jobs = [job]\n    }\n  } else {\n    let defaultProcessingOrder: Sort =\n      payload.collections[jobsCollectionSlug]?.config.defaultSort ?? 'createdAt'\n\n    const processingOrderConfig = jobsConfig.processingOrder\n    if (typeof processingOrderConfig === 'function') {\n      defaultProcessingOrder = await processingOrderConfig(args)\n    } else if (typeof processingOrderConfig === 'object' && !Array.isArray(processingOrderConfig)) {\n      if (\n        !allQueues &&\n        queue &&\n        processingOrderConfig.queues &&\n        processingOrderConfig.queues[queue]\n      ) {\n        defaultProcessingOrder = processingOrderConfig.queues[queue]\n      } else if (processingOrderConfig.default) {\n        defaultProcessingOrder = processingOrderConfig.default\n      }\n    } else if (typeof processingOrderConfig === 'string') {\n      defaultProcessingOrder = processingOrderConfig\n    }\n    const updatedDocs = await updateJobs({\n      data: {\n        processing: true,\n      },\n      depth: jobsConfig.depth,\n      disableTransaction: true,\n      limit,\n      req,\n      returning: true,\n      sort: processingOrder ?? defaultProcessingOrder,\n      where: { and },\n    })\n\n    if (updatedDocs) {\n      jobs = updatedDocs\n    }\n  }\n\n  /**\n   * Just for logging purposes, we want to know how many jobs are new and how many are existing (= already been tried).\n   * This is only for logs - in the end we still want to run all jobs, regardless of whether they are new or existing.\n   */\n  const { existingJobs, newJobs } = jobs.reduce(\n    (acc, job) => {\n      if (job.totalTried > 0) {\n        acc.existingJobs.push(job)\n      } else {\n        acc.newJobs.push(job)\n      }\n      return acc\n    },\n    { existingJobs: [] as Job[], newJobs: [] as Job[] },\n  )\n\n  if (!jobs.length) {\n    return {\n      noJobsRemaining: true,\n      remainingJobsFromQueried: 0,\n    }\n  }\n\n  if (!silent || (typeof silent === 'object' && !silent.info)) {\n    payload.logger.info({\n      msg: `Running ${jobs.length} jobs.`,\n      new: newJobs?.length,\n      retrying: existingJobs?.length,\n    })\n  }\n\n  const successfullyCompletedJobs: (number | string)[] = []\n\n  const runSingleJob = async (\n    job: Job,\n  ): Promise<{\n    id: number | string\n    result: RunJobResult\n  }> => {\n    if (!job.workflowSlug && !job.taskSlug) {\n      throw new Error('Job must have either a workflowSlug or a taskSlug')\n    }\n    const jobReq = isolateObjectProperty(req, 'transactionID')\n\n    const workflowConfig: WorkflowConfig =\n      job.workflowSlug && jobsConfig.workflows?.length\n        ? jobsConfig.workflows.find(({ slug }) => slug === job.workflowSlug)!\n        : {\n            slug: 'singleTask',\n            handler: async ({ job, tasks }) => {\n              await tasks[job.taskSlug as string]!('1', {\n                input: job.input,\n              })\n            },\n          }\n\n    if (!workflowConfig) {\n      return {\n        id: job.id,\n        result: {\n          status: 'error',\n        },\n      } // Skip jobs with no workflow configuration\n    }\n\n    try {\n      const updateJob = getUpdateJobFunction(job, jobReq)\n\n      // the runner will either be passed to the config\n      // OR it will be a path, which we will need to import via eval to avoid\n      // Next.js compiler dynamic import expression errors\n      let workflowHandler: WorkflowHandler | WorkflowJSON\n      if (\n        typeof workflowConfig.handler === 'function' ||\n        (typeof workflowConfig.handler === 'object' && Array.isArray(workflowConfig.handler))\n      ) {\n        workflowHandler = workflowConfig.handler\n      } else {\n        workflowHandler = await importHandlerPath<typeof workflowHandler>(workflowConfig.handler)\n\n        if (!workflowHandler) {\n          const jobLabel = job.workflowSlug || `Task: ${job.taskSlug}`\n          const errorMessage = `Can't find runner while importing with the path ${workflowConfig.handler} in job type ${jobLabel}.`\n          if (!silent || (typeof silent === 'object' && !silent.error)) {\n            payload.logger.error(errorMessage)\n          }\n\n          await updateJob({\n            error: {\n              error: errorMessage,\n            },\n            hasError: true,\n            processing: false,\n          })\n\n          return {\n            id: job.id,\n            result: {\n              status: 'error-reached-max-retries',\n            },\n          }\n        }\n      }\n\n      if (typeof workflowHandler === 'function') {\n        const result = await runJob({\n          job,\n          req: jobReq,\n          silent,\n          updateJob,\n          workflowConfig,\n          workflowHandler,\n        })\n\n        if (result.status === 'success') {\n          successfullyCompletedJobs.push(job.id)\n        }\n\n        return { id: job.id, result }\n      } else {\n        const result = await runJSONJob({\n          job,\n          req: jobReq,\n          silent,\n          updateJob,\n          workflowConfig,\n          workflowHandler,\n        })\n\n        if (result.status === 'success') {\n          successfullyCompletedJobs.push(job.id)\n        }\n\n        return { id: job.id, result }\n      }\n    } catch (error) {\n      if (error instanceof JobCancelledError) {\n        return {\n          id: job.id,\n          result: {\n            status: 'error-reached-max-retries',\n          },\n        }\n      }\n      throw error\n    }\n  }\n\n  let resultsArray: { id: number | string; result: RunJobResult }[] = []\n  if (sequential) {\n    for (const job of jobs) {\n      const result = await runSingleJob(job)\n      if (result) {\n        resultsArray.push(result)\n      }\n    }\n  } else {\n    const jobPromises = jobs.map(runSingleJob)\n    resultsArray = (await Promise.all(jobPromises)) as {\n      id: number | string\n      result: RunJobResult\n    }[]\n  }\n\n  if (jobsConfig.deleteJobOnComplete && successfullyCompletedJobs.length) {\n    try {\n      if (jobsConfig.runHooks) {\n        await payload.delete({\n          collection: jobsCollectionSlug,\n          depth: 0, // can be 0 since we're not returning anything\n          disableTransaction: true,\n          where: { id: { in: successfullyCompletedJobs } },\n        })\n      } else {\n        await payload.db.deleteMany({\n          collection: jobsCollectionSlug,\n          where: { id: { in: successfullyCompletedJobs } },\n        })\n      }\n    } catch (err) {\n      if (!silent || (typeof silent === 'object' && !silent.error)) {\n        payload.logger.error({\n          err,\n          msg: `Failed to delete jobs ${successfullyCompletedJobs.join(', ')} on complete`,\n        })\n      }\n    }\n  }\n\n  const resultsObject: RunJobsResult['jobStatus'] = resultsArray.reduce(\n    (acc, cur) => {\n      if (cur !== null) {\n        // Check if there's a valid result to include\n        acc[cur.id] = cur.result\n      }\n      return acc\n    },\n    {} as Record<string, RunJobResult>,\n  )\n\n  let remainingJobsFromQueried = 0\n  for (const jobID in resultsObject) {\n    const jobResult = resultsObject[jobID]\n    if (jobResult?.status === 'error') {\n      remainingJobsFromQueried++ // Can be retried\n    }\n  }\n\n  return {\n    jobStatus: resultsObject,\n    remainingJobsFromQueried,\n  }\n}\n"],"names":["Forbidden","isolateObjectProperty","jobsCollectionSlug","JobCancelledError","getCurrentDate","updateJob","updateJobs","getUpdateJobFunction","importHandlerPath","runJob","runJSONJob","runJobs","args","id","allQueues","limit","overrideAccess","processingOrder","queue","req","payload","config","jobs","jobsConfig","sequential","silent","where","whereFromProps","accessFn","access","run","hasAccess","t","and","completedAt","exists","hasError","not_equals","processing","equals","or","waitUntil","less_than","toISOString","push","job","data","depth","disableTransaction","returning","defaultProcessingOrder","collections","defaultSort","processingOrderConfig","Array","isArray","queues","default","updatedDocs","sort","existingJobs","newJobs","reduce","acc","totalTried","length","noJobsRemaining","remainingJobsFromQueried","info","logger","msg","new","retrying","successfullyCompletedJobs","runSingleJob","workflowSlug","taskSlug","Error","jobReq","workflowConfig","workflows","find","slug","handler","tasks","input","result","status","workflowHandler","jobLabel","errorMessage","error","resultsArray","jobPromises","map","Promise","all","deleteJobOnComplete","runHooks","delete","collection","in","db","deleteMany","err","join","resultsObject","cur","jobID","jobResult","jobStatus"],"mappings":";;;;AAOA,SAASA,SAAS,QAAQ,+BAA8B;AACxD,SAASC,qBAAqB,QAAQ,8CAA6C;AACnF,SAASC,kBAAkB,QAAQ,6BAA4B;AAC/D,SAASC,iBAAiB,QAAQ,wBAAuB;AACzD,SAASC,cAAc,QAAQ,oCAAmC;AAClE,SAASC,SAAS,EAAEC,UAAU,QAAQ,+BAA8B;AACpE,SAASC,oBAAoB,QAAQ,mCAAkC;AACvE,SAASC,iBAAiB,QAAQ,gCAA+B;AACjE,SAASC,MAAM,QAAQ,oBAAmB;AAC1C,SAASC,UAAU,QAAQ,wBAAuB;;;;;;;;;;;AAiE3C,MAAMC,UAAU,OAAOC;IAC5B,MAAM,EACJC,EAAE,EACFC,YAAY,KAAK,EACjBC,QAAQ,EAAE,EACVC,cAAc,EACdC,eAAe,EACfC,QAAQ,SAAS,EACjBC,GAAG,EACHA,KAAK,EACHC,OAAO,EACPA,SAAS,EACPC,QAAQ,EAAEC,MAAMC,UAAU,EAAE,EAC7B,EACF,EACDC,UAAU,EACVC,SAAS,KAAK,EACdC,OAAOC,cAAc,EACtB,GAAGf;IAEJ,IAAI,CAACI,gBAAgB;QACnB;;KAEC,GACD,MAAMY,WAAWL,YAAYM,QAAQC,OAAQ,CAAA,IAAM,IAAG;QACtD,MAAMC,YAAY,MAAMH,SAAS;YAAET;QAAI;QACvC,IAAI,CAACY,WAAW;YACd,MAAM,IAAI/B,6QAAAA,CAAUmB,IAAIa,CAAC;QAC3B;IACF;IACA,MAAMC,MAAe;QACnB;YACEC,aAAa;gBACXC,QAAQ;YACV;QACF;QACA;YACEC,UAAU;gBACRC,YAAY;YACd;QACF;QACA;YACEC,YAAY;gBACVC,QAAQ;YACV;QACF;QACA;YACEC,IAAI;gBACF;oBACEC,WAAW;wBACTN,QAAQ;oBACV;gBACF;gBACA;oBACEM,WAAW;wBACTC,eAAWtC,oSAAAA,IAAiBuC,WAAW;oBACzC;gBACF;aACD;QACH;KACD;IAED,IAAI7B,cAAc,MAAM;QACtBmB,IAAIW,IAAI,CAAC;YACP1B,OAAO;gBACLqB,QAAQrB,SAAS;YACnB;QACF;IACF;IAEA,IAAIS,gBAAgB;QAClBM,IAAIW,IAAI,CAACjB;IACX;IAEA,uGAAuG;IACvG,iDAAiD;IACjD,IAAIL,OAAc,EAAE;IAEpB,IAAIT,IAAI;QACN,sBAAsB;QACtB,MAAMgC,MAAM,UAAMxC,0RAAAA,EAAU;YAC1BQ;YACAiC,MAAM;gBACJR,YAAY;YACd;YACAS,OAAOxB,WAAWwB,KAAK;YACvBC,oBAAoB;YACpB7B;YACA8B,WAAW;QACb;QACA,IAAIJ,KAAK;YACPvB,OAAO;gBAACuB;aAAI;QACd;IACF,OAAO;QACL,IAAIK,yBACF9B,QAAQ+B,WAAW,CAACjD,iSAAAA,CAAmB,EAAEmB,OAAO+B,eAAe;QAEjE,MAAMC,wBAAwB9B,WAAWN,eAAe;QACxD,IAAI,OAAOoC,0BAA0B,YAAY;YAC/CH,yBAAyB,MAAMG,sBAAsBzC;QACvD,OAAO,IAAI,OAAOyC,0BAA0B,YAAY,CAACC,MAAMC,OAAO,CAACF,wBAAwB;YAC7F,IACE,CAACvC,aACDI,SACAmC,sBAAsBG,MAAM,IAC5BH,sBAAsBG,MAAM,CAACtC,MAAM,EACnC;gBACAgC,yBAAyBG,sBAAsBG,MAAM,CAACtC,MAAM;YAC9D,OAAO,IAAImC,sBAAsBI,OAAO,EAAE;gBACxCP,yBAAyBG,sBAAsBI,OAAO;YACxD;QACF,OAAO,IAAI,OAAOJ,0BAA0B,UAAU;YACpDH,yBAAyBG;QAC3B;QACA,MAAMK,cAAc,UAAMpD,2RAAAA,EAAW;YACnCwC,MAAM;gBACJR,YAAY;YACd;YACAS,OAAOxB,WAAWwB,KAAK;YACvBC,oBAAoB;YACpBjC;YACAI;YACA8B,WAAW;YACXU,MAAM1C,mBAAmBiC;YACzBxB,OAAO;gBAAEO;YAAI;QACf;QAEA,IAAIyB,aAAa;YACfpC,OAAOoC;QACT;IACF;IAEA;;;GAGC,GACD,MAAM,EAAEE,YAAY,EAAEC,OAAO,EAAE,GAAGvC,KAAKwC,MAAM,CAC3C,CAACC,KAAKlB;QACJ,IAAIA,IAAImB,UAAU,GAAG,GAAG;YACtBD,IAAIH,YAAY,CAAChB,IAAI,CAACC;QACxB,OAAO;YACLkB,IAAIF,OAAO,CAACjB,IAAI,CAACC;QACnB;QACA,OAAOkB;IACT,GACA;QAAEH,cAAc,EAAE;QAAWC,SAAS,EAAE;IAAU;IAGpD,IAAI,CAACvC,KAAK2C,MAAM,EAAE;QAChB,OAAO;YACLC,iBAAiB;YACjBC,0BAA0B;QAC5B;IACF;IAEA,IAAI,CAAC1C,UAAW,OAAOA,WAAW,YAAY,CAACA,OAAO2C,IAAI,EAAG;QAC3DhD,QAAQiD,MAAM,CAACD,IAAI,CAAC;YAClBE,KAAK,CAAC,QAAQ,EAAEhD,KAAK2C,MAAM,CAAC,MAAM,CAAC;YACnCM,KAAKV,SAASI;YACdO,UAAUZ,cAAcK;QAC1B;IACF;IAEA,MAAMQ,4BAAiD,EAAE;IAEzD,MAAMC,eAAe,OACnB7B;QAKA,IAAI,CAACA,IAAI8B,YAAY,IAAI,CAAC9B,IAAI+B,QAAQ,EAAE;YACtC,MAAM,IAAIC,MAAM;QAClB;QACA,MAAMC,aAAS7E,wSAAAA,EAAsBkB,KAAK;QAE1C,MAAM4D,iBACJlC,IAAI8B,YAAY,IAAIpD,WAAWyD,SAAS,EAAEf,SACtC1C,WAAWyD,SAAS,CAACC,IAAI,CAAC,CAAC,EAAEC,IAAI,EAAE,GAAKA,SAASrC,IAAI8B,YAAY,IACjE;YACEO,MAAM;YACNC,SAAS,OAAO,EAAEtC,GAAG,EAAEuC,KAAK,EAAE;gBAC5B,MAAMA,KAAK,CAACvC,IAAI+B,QAAQ,CAAW,CAAE,KAAK;oBACxCS,OAAOxC,IAAIwC,KAAK;gBAClB;YACF;QACF;QAEN,IAAI,CAACN,gBAAgB;YACnB,OAAO;gBACLlE,IAAIgC,IAAIhC,EAAE;gBACVyE,QAAQ;oBACNC,QAAQ;gBACV;YACF,EAAE,2CAA2C;;QAC/C;QAEA,IAAI;YACF,MAAMlF,gBAAYE,sUAAAA,EAAqBsC,KAAKiC;YAE5C,iDAAiD;YACjD,uEAAuE;YACvE,oDAAoD;YACpD,IAAIU;YACJ,IACE,OAAOT,eAAeI,OAAO,KAAK,cACjC,OAAOJ,eAAeI,OAAO,KAAK,YAAY7B,MAAMC,OAAO,CAACwB,eAAeI,OAAO,GACnF;gBACAK,kBAAkBT,eAAeI,OAAO;YAC1C,OAAO;gBACLK,kBAAkB,UAAMhF,gUAAAA,EAA0CuE,eAAeI,OAAO;gBAExF,IAAI,CAACK,iBAAiB;oBACpB,MAAMC,WAAW5C,IAAI8B,YAAY,IAAI,CAAC,MAAM,EAAE9B,IAAI+B,QAAQ,EAAE;oBAC5D,MAAMc,eAAe,CAAC,gDAAgD,EAAEX,eAAeI,OAAO,CAAC,aAAa,EAAEM,SAAS,CAAC,CAAC;oBACzH,IAAI,CAAChE,UAAW,OAAOA,WAAW,YAAY,CAACA,OAAOkE,KAAK,EAAG;wBAC5DvE,QAAQiD,MAAM,CAACsB,KAAK,CAACD;oBACvB;oBAEA,MAAMrF,UAAU;wBACdsF,OAAO;4BACLA,OAAOD;wBACT;wBACAtD,UAAU;wBACVE,YAAY;oBACd;oBAEA,OAAO;wBACLzB,IAAIgC,IAAIhC,EAAE;wBACVyE,QAAQ;4BACNC,QAAQ;wBACV;oBACF;gBACF;YACF;YAEA,IAAI,OAAOC,oBAAoB,YAAY;gBACzC,MAAMF,SAAS,UAAM7E,ySAAAA,EAAO;oBAC1BoC;oBACA1B,KAAK2D;oBACLrD;oBACApB;oBACA0E;oBACAS;gBACF;gBAEA,IAAIF,OAAOC,MAAM,KAAK,WAAW;oBAC/Bd,0BAA0B7B,IAAI,CAACC,IAAIhC,EAAE;gBACvC;gBAEA,OAAO;oBAAEA,IAAIgC,IAAIhC,EAAE;oBAAEyE;gBAAO;YAC9B,OAAO;gBACL,MAAMA,SAAS,UAAM5E,iTAAAA,EAAW;oBAC9BmC;oBACA1B,KAAK2D;oBACLrD;oBACApB;oBACA0E;oBACAS;gBACF;gBAEA,IAAIF,OAAOC,MAAM,KAAK,WAAW;oBAC/Bd,0BAA0B7B,IAAI,CAACC,IAAIhC,EAAE;gBACvC;gBAEA,OAAO;oBAAEA,IAAIgC,IAAIhC,EAAE;oBAAEyE;gBAAO;YAC9B;QACF,EAAE,OAAOK,OAAO;YACd,IAAIA,iBAAiBxF,2RAAAA,EAAmB;gBACtC,OAAO;oBACLU,IAAIgC,IAAIhC,EAAE;oBACVyE,QAAQ;wBACNC,QAAQ;oBACV;gBACF;YACF;YACA,MAAMI;QACR;IACF;IAEA,IAAIC,eAAgE,EAAE;IACtE,IAAIpE,YAAY;QACd,KAAK,MAAMqB,OAAOvB,KAAM;YACtB,MAAMgE,SAAS,MAAMZ,aAAa7B;YAClC,IAAIyC,QAAQ;gBACVM,aAAahD,IAAI,CAAC0C;YACpB;QACF;IACF,OAAO;QACL,MAAMO,cAAcvE,KAAKwE,GAAG,CAACpB;QAC7BkB,eAAgB,MAAMG,QAAQC,GAAG,CAACH;IAIpC;IAEA,IAAItE,WAAW0E,mBAAmB,IAAIxB,0BAA0BR,MAAM,EAAE;QACtE,IAAI;YACF,IAAI1C,WAAW2E,QAAQ,EAAE;gBACvB,MAAM9E,QAAQ+E,MAAM,CAAC;oBACnBC,YAAYlG,iSAAAA;oBACZ6C,OAAO;oBACPC,oBAAoB;oBACpBtB,OAAO;wBAAEb,IAAI;4BAAEwF,IAAI5B;wBAA0B;oBAAE;gBACjD;YACF,OAAO;gBACL,MAAMrD,QAAQkF,EAAE,CAACC,UAAU,CAAC;oBAC1BH,YAAYlG,iSAAAA;oBACZwB,OAAO;wBAAEb,IAAI;4BAAEwF,IAAI5B;wBAA0B;oBAAE;gBACjD;YACF;QACF,EAAE,OAAO+B,KAAK;YACZ,IAAI,CAAC/E,UAAW,OAAOA,WAAW,YAAY,CAACA,OAAOkE,KAAK,EAAG;gBAC5DvE,QAAQiD,MAAM,CAACsB,KAAK,CAAC;oBACnBa;oBACAlC,KAAK,CAAC,sBAAsB,EAAEG,0BAA0BgC,IAAI,CAAC,MAAM,YAAY,CAAC;gBAClF;YACF;QACF;IACF;IAEA,MAAMC,gBAA4Cd,aAAa9B,MAAM,CACnE,CAACC,KAAK4C;QACJ,IAAIA,QAAQ,MAAM;YAChB,6CAA6C;YAC7C5C,GAAG,CAAC4C,IAAI9F,EAAE,CAAC,GAAG8F,IAAIrB,MAAM;QAC1B;QACA,OAAOvB;IACT,GACA,CAAC;IAGH,IAAII,2BAA2B;IAC/B,IAAK,MAAMyC,SAASF,cAAe;QACjC,MAAMG,YAAYH,aAAa,CAACE,MAAM;QACtC,IAAIC,WAAWtB,WAAW,SAAS;YACjCpB,2BAA2B,iBAAiB;;QAC9C;IACF;IAEA,OAAO;QACL2C,WAAWJ;QACXvC;IACF;AACF,EAAC"}},
    {"offset": {"line": 1697, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/endpoints/run.ts"],"sourcesContent":["import type { Endpoint } from '../../config/types.js'\nimport type { SanitizedJobsConfig } from '../config/types/index.js'\n\nimport { runJobs, type RunJobsArgs } from '../operations/runJobs/index.js'\n\n/**\n * /api/payload-jobs/run endpoint\n *\n * This endpoint is GET instead of POST to allow it to be used in a Vercel Cron.\n */\nexport const runJobsEndpoint: Endpoint = {\n  handler: async (req) => {\n    const jobsConfig = req.payload.config.jobs\n\n    if (!configHasJobs(jobsConfig)) {\n      return Response.json(\n        {\n          message: 'No jobs to run.',\n        },\n        { status: 200 },\n      )\n    }\n\n    const accessFn = jobsConfig.access?.run ?? (() => true)\n\n    const hasAccess = await accessFn({ req })\n\n    if (!hasAccess) {\n      return Response.json(\n        {\n          message: req.i18n.t('error:unauthorized'),\n        },\n        { status: 401 },\n      )\n    }\n\n    const {\n      allQueues,\n      disableScheduling: disableSchedulingParam,\n      limit,\n      queue,\n      silent: silentParam,\n    } = req.query as {\n      allQueues?: 'false' | 'true'\n      disableScheduling?: 'false' | 'true'\n      limit?: number\n      queue?: string\n      silent?: string\n    }\n\n    const silent = silentParam === 'true'\n\n    const shouldHandleSchedules = disableSchedulingParam !== 'true'\n\n    const runAllQueues = allQueues && !(typeof allQueues === 'string' && allQueues === 'false')\n\n    if (shouldHandleSchedules && jobsConfig.scheduling) {\n      // If should handle schedules and schedules are defined\n      await req.payload.jobs.handleSchedules({ allQueues: runAllQueues, queue, req })\n    }\n\n    const runJobsArgs: RunJobsArgs = {\n      queue,\n      req,\n      // Access is validated above, so it's safe to override here\n      allQueues: runAllQueues,\n      overrideAccess: true,\n      silent,\n    }\n\n    if (typeof queue === 'string') {\n      runJobsArgs.queue = queue\n    }\n\n    const parsedLimit = Number(limit)\n    if (!isNaN(parsedLimit)) {\n      runJobsArgs.limit = parsedLimit\n    }\n\n    let noJobsRemaining = false\n    let remainingJobsFromQueried = 0\n    try {\n      const result = await runJobs(runJobsArgs)\n      noJobsRemaining = !!result.noJobsRemaining\n      remainingJobsFromQueried = result.remainingJobsFromQueried\n    } catch (err) {\n      req.payload.logger.error({\n        err,\n        msg: 'There was an error running jobs:',\n        queue: runJobsArgs.queue,\n      })\n\n      return Response.json(\n        {\n          message: req.i18n.t('error:unknown'),\n          noJobsRemaining: true,\n          remainingJobsFromQueried,\n        },\n        { status: 500 },\n      )\n    }\n\n    return Response.json(\n      {\n        message: req.i18n.t('general:success'),\n        noJobsRemaining,\n        remainingJobsFromQueried,\n      },\n      { status: 200 },\n    )\n  },\n  method: 'get',\n  path: '/run',\n}\n\nexport const configHasJobs = (jobsConfig: SanitizedJobsConfig): boolean => {\n  return Boolean(jobsConfig.tasks?.length || jobsConfig.workflows?.length)\n}\n"],"names":["runJobs","runJobsEndpoint","handler","req","jobsConfig","payload","config","jobs","configHasJobs","Response","json","message","status","accessFn","access","run","hasAccess","i18n","t","allQueues","disableScheduling","disableSchedulingParam","limit","queue","silent","silentParam","query","shouldHandleSchedules","runAllQueues","scheduling","handleSchedules","runJobsArgs","overrideAccess","parsedLimit","Number","isNaN","noJobsRemaining","remainingJobsFromQueried","result","err","logger","error","msg","method","path","Boolean","tasks","length","workflows"],"mappings":";;;;;;AAGA,SAASA,OAAO,QAA0B,iCAAgC;;AAOnE,MAAMC,kBAA4B;IACvCC,SAAS,OAAOC;QACd,MAAMC,aAAaD,IAAIE,OAAO,CAACC,MAAM,CAACC,IAAI;QAE1C,IAAI,CAACC,cAAcJ,aAAa;YAC9B,OAAOK,SAASC,IAAI,CAClB;gBACEC,SAAS;YACX,GACA;gBAAEC,QAAQ;YAAI;QAElB;QAEA,MAAMC,WAAWT,WAAWU,MAAM,EAAEC,OAAQ,CAAA,IAAM,IAAG;QAErD,MAAMC,YAAY,MAAMH,SAAS;YAAEV;QAAI;QAEvC,IAAI,CAACa,WAAW;YACd,OAAOP,SAASC,IAAI,CAClB;gBACEC,SAASR,IAAIc,IAAI,CAACC,CAAC,CAAC;YACtB,GACA;gBAAEN,QAAQ;YAAI;QAElB;QAEA,MAAM,EACJO,SAAS,EACTC,mBAAmBC,sBAAsB,EACzCC,KAAK,EACLC,KAAK,EACLC,QAAQC,WAAW,EACpB,GAAGtB,IAAIuB,KAAK;QAQb,MAAMF,SAASC,gBAAgB;QAE/B,MAAME,wBAAwBN,2BAA2B;QAEzD,MAAMO,eAAeT,aAAa,CAAE,CAAA,OAAOA,cAAc,YAAYA,cAAc,OAAM;QAEzF,IAAIQ,yBAAyBvB,WAAWyB,UAAU,EAAE;YAClD,uDAAuD;YACvD,MAAM1B,IAAIE,OAAO,CAACE,IAAI,CAACuB,eAAe,CAAC;gBAAEX,WAAWS;gBAAcL;gBAAOpB;YAAI;QAC/E;QAEA,MAAM4B,cAA2B;YAC/BR;YACApB;YACA,2DAA2D;YAC3DgB,WAAWS;YACXI,gBAAgB;YAChBR;QACF;QAEA,IAAI,OAAOD,UAAU,UAAU;YAC7BQ,YAAYR,KAAK,GAAGA;QACtB;QAEA,MAAMU,cAAcC,OAAOZ;QAC3B,IAAI,CAACa,MAAMF,cAAc;YACvBF,YAAYT,KAAK,GAAGW;QACtB;QAEA,IAAIG,kBAAkB;QACtB,IAAIC,2BAA2B;QAC/B,IAAI;YACF,MAAMC,SAAS,UAAMtC,gSAAAA,EAAQ+B;YAC7BK,kBAAkB,CAAC,CAACE,OAAOF,eAAe;YAC1CC,2BAA2BC,OAAOD,wBAAwB;QAC5D,EAAE,OAAOE,KAAK;YACZpC,IAAIE,OAAO,CAACmC,MAAM,CAACC,KAAK,CAAC;gBACvBF;gBACAG,KAAK;gBACLnB,OAAOQ,YAAYR,KAAK;YAC1B;YAEA,OAAOd,SAASC,IAAI,CAClB;gBACEC,SAASR,IAAIc,IAAI,CAACC,CAAC,CAAC;gBACpBkB,iBAAiB;gBACjBC;YACF,GACA;gBAAEzB,QAAQ;YAAI;QAElB;QAEA,OAAOH,SAASC,IAAI,CAClB;YACEC,SAASR,IAAIc,IAAI,CAACC,CAAC,CAAC;YACpBkB;YACAC;QACF,GACA;YAAEzB,QAAQ;QAAI;IAElB;IACA+B,QAAQ;IACRC,MAAM;AACR,EAAC;AAEM,MAAMpC,gBAAgB,CAACJ;IAC5B,OAAOyC,QAAQzC,WAAW0C,KAAK,EAAEC,UAAU3C,WAAW4C,SAAS,EAAED;AACnE,EAAC"}},
    {"offset": {"line": 1791, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/endpoints/handleSchedules.ts"],"sourcesContent":["import type { Endpoint } from '../../config/types.js'\n\nimport { handleSchedules } from '../operations/handleSchedules/index.js'\nimport { configHasJobs } from './run.js'\n\n/**\n * GET /api/payload-jobs/handle-schedules endpoint\n *\n * This endpoint is GET instead of POST to allow it to be used in a Vercel Cron.\n */\nexport const handleSchedulesJobsEndpoint: Endpoint = {\n  handler: async (req) => {\n    const jobsConfig = req.payload.config.jobs\n\n    if (!configHasJobs(jobsConfig)) {\n      return Response.json(\n        {\n          message: 'No jobs to schedule.',\n        },\n        { status: 200 },\n      )\n    }\n\n    const accessFn = jobsConfig.access?.run ?? (() => true)\n\n    const hasAccess = await accessFn({ req })\n\n    if (!hasAccess) {\n      return Response.json(\n        {\n          message: req.i18n.t('error:unauthorized'),\n        },\n        { status: 401 },\n      )\n    }\n\n    if (!jobsConfig.scheduling) {\n      // There is no reason to call the handleSchedules endpoint if the stats global is not enabled (= no schedules defined)\n      return Response.json(\n        {\n          message:\n            'Cannot handle schedules because no tasks or workflows with schedules are defined.',\n        },\n        { status: 500 },\n      )\n    }\n\n    const { allQueues, queue } = req.query as {\n      allQueues?: 'false' | 'true'\n      queue?: string\n    }\n\n    const runAllQueues = allQueues && !(typeof allQueues === 'string' && allQueues === 'false')\n\n    const { errored, queued, skipped } = await handleSchedules({\n      allQueues: runAllQueues,\n      queue,\n      req,\n    })\n\n    return Response.json(\n      {\n        errored,\n        message: req.i18n.t('general:success'),\n        queued,\n        skipped,\n      },\n      { status: 200 },\n    )\n  },\n  method: 'get',\n  path: '/handle-schedules',\n}\n"],"names":["handleSchedules","configHasJobs","handleSchedulesJobsEndpoint","handler","req","jobsConfig","payload","config","jobs","Response","json","message","status","accessFn","access","run","hasAccess","i18n","t","scheduling","allQueues","queue","query","runAllQueues","errored","queued","skipped","method","path"],"mappings":";;;;AAEA,SAASA,eAAe,QAAQ,yCAAwC;AACxE,SAASC,aAAa,QAAQ,WAAU;;;AAOjC,MAAMC,8BAAwC;IACnDC,SAAS,OAAOC;QACd,MAAMC,aAAaD,IAAIE,OAAO,CAACC,MAAM,CAACC,IAAI;QAE1C,IAAI,KAACP,wRAAAA,EAAcI,aAAa;YAC9B,OAAOI,SAASC,IAAI,CAClB;gBACEC,SAAS;YACX,GACA;gBAAEC,QAAQ;YAAI;QAElB;QAEA,MAAMC,WAAWR,WAAWS,MAAM,EAAEC,OAAQ,CAAA,IAAM,IAAG;QAErD,MAAMC,YAAY,MAAMH,SAAS;YAAET;QAAI;QAEvC,IAAI,CAACY,WAAW;YACd,OAAOP,SAASC,IAAI,CAClB;gBACEC,SAASP,IAAIa,IAAI,CAACC,CAAC,CAAC;YACtB,GACA;gBAAEN,QAAQ;YAAI;QAElB;QAEA,IAAI,CAACP,WAAWc,UAAU,EAAE;YAC1B,sHAAsH;YACtH,OAAOV,SAASC,IAAI,CAClB;gBACEC,SACE;YACJ,GACA;gBAAEC,QAAQ;YAAI;QAElB;QAEA,MAAM,EAAEQ,SAAS,EAAEC,KAAK,EAAE,GAAGjB,IAAIkB,KAAK;QAKtC,MAAMC,eAAeH,aAAa,CAAE,CAAA,OAAOA,cAAc,YAAYA,cAAc,OAAM;QAEzF,MAAM,EAAEI,OAAO,EAAEC,MAAM,EAAEC,OAAO,EAAE,GAAG,UAAM1B,gTAAAA,EAAgB;YACzDoB,WAAWG;YACXF;YACAjB;QACF;QAEA,OAAOK,SAASC,IAAI,CAClB;YACEc;YACAb,SAASP,IAAIa,IAAI,CAACC,CAAC,CAAC;YACpBO;YACAC;QACF,GACA;YAAEd,QAAQ;QAAI;IAElB;IACAe,QAAQ;IACRC,MAAM;AACR,EAAC"}},
    {"offset": {"line": 1851, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/utilities/getJobTaskStatus.ts"],"sourcesContent":["import type { Job } from '../../index.js'\nimport type { JobTaskStatus } from '../config/types/workflowTypes.js'\n\ntype Args = {\n  jobLog: Job['log']\n}\n\nexport const getJobTaskStatus = ({ jobLog }: Args): JobTaskStatus => {\n  const taskStatus: JobTaskStatus = {}\n\n  if (!jobLog || !Array.isArray(jobLog)) {\n    return taskStatus\n  }\n\n  // First, add (in order) the steps from the config to\n  // our status map\n  for (const loggedJob of jobLog) {\n    if (!taskStatus[loggedJob.taskSlug]) {\n      taskStatus[loggedJob.taskSlug] = {}\n    }\n    if (!taskStatus[loggedJob.taskSlug]?.[loggedJob.taskID]) {\n      taskStatus[loggedJob.taskSlug]![loggedJob.taskID] = {\n        complete: loggedJob.state === 'succeeded',\n        input: loggedJob.input,\n        output: loggedJob.output,\n        taskSlug: loggedJob.taskSlug,\n        totalTried: 1,\n      }\n    } else {\n      const newTaskStatus = taskStatus[loggedJob.taskSlug]![loggedJob.taskID]!\n      newTaskStatus.totalTried += 1\n\n      if (loggedJob.state === 'succeeded') {\n        newTaskStatus.complete = true\n        // As the task currently saved in taskStatus has likely failed and thus has no\n        // Output data, we need to update it with the new data from the successful task\n        newTaskStatus.output = loggedJob.output\n        newTaskStatus.input = loggedJob.input\n        newTaskStatus.taskSlug = loggedJob.taskSlug\n      }\n      taskStatus[loggedJob.taskSlug]![loggedJob.taskID] = newTaskStatus\n    }\n  }\n\n  return taskStatus\n}\n"],"names":["getJobTaskStatus","jobLog","taskStatus","Array","isArray","loggedJob","taskSlug","taskID","complete","state","input","output","totalTried","newTaskStatus"],"mappings":";;;;AAOO,MAAMA,mBAAmB,CAAC,EAAEC,MAAM,EAAQ;IAC/C,MAAMC,aAA4B,CAAC;IAEnC,IAAI,CAACD,UAAU,CAACE,MAAMC,OAAO,CAACH,SAAS;QACrC,OAAOC;IACT;IAEA,qDAAqD;IACrD,iBAAiB;IACjB,KAAK,MAAMG,aAAaJ,OAAQ;QAC9B,IAAI,CAACC,UAAU,CAACG,UAAUC,QAAQ,CAAC,EAAE;YACnCJ,UAAU,CAACG,UAAUC,QAAQ,CAAC,GAAG,CAAC;QACpC;QACA,IAAI,CAACJ,UAAU,CAACG,UAAUC,QAAQ,CAAC,EAAE,CAACD,UAAUE,MAAM,CAAC,EAAE;YACvDL,UAAU,CAACG,UAAUC,QAAQ,CAAE,CAACD,UAAUE,MAAM,CAAC,GAAG;gBAClDC,UAAUH,UAAUI,KAAK,KAAK;gBAC9BC,OAAOL,UAAUK,KAAK;gBACtBC,QAAQN,UAAUM,MAAM;gBACxBL,UAAUD,UAAUC,QAAQ;gBAC5BM,YAAY;YACd;QACF,OAAO;YACL,MAAMC,gBAAgBX,UAAU,CAACG,UAAUC,QAAQ,CAAE,CAACD,UAAUE,MAAM,CAAC;YACvEM,cAAcD,UAAU,IAAI;YAE5B,IAAIP,UAAUI,KAAK,KAAK,aAAa;gBACnCI,cAAcL,QAAQ,GAAG;gBACzB,8EAA8E;gBAC9E,+EAA+E;gBAC/EK,cAAcF,MAAM,GAAGN,UAAUM,MAAM;gBACvCE,cAAcH,KAAK,GAAGL,UAAUK,KAAK;gBACrCG,cAAcP,QAAQ,GAAGD,UAAUC,QAAQ;YAC7C;YACAJ,UAAU,CAACG,UAAUC,QAAQ,CAAE,CAACD,UAAUE,MAAM,CAAC,GAAGM;QACtD;IACF;IAEA,OAAOX;AACT,EAAC"}},
    {"offset": {"line": 1894, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/config/collection.ts"],"sourcesContent":["import type { CollectionConfig } from '../../collections/config/types.js'\nimport type { SanitizedConfig } from '../../config/types.js'\nimport type { Field } from '../../fields/config/types.js'\nimport type { Job } from '../../index.js'\n\nimport { handleSchedulesJobsEndpoint } from '../endpoints/handleSchedules.js'\nimport { runJobsEndpoint } from '../endpoints/run.js'\nimport { getJobTaskStatus } from '../utilities/getJobTaskStatus.js'\n\nexport const jobsCollectionSlug = 'payload-jobs'\n\nexport const getDefaultJobsCollection: (jobsConfig: SanitizedConfig['jobs']) => CollectionConfig = (\n  jobsConfig,\n) => {\n  const workflowSlugs: Set<string> = new Set()\n  const taskSlugs: Set<string> = new Set(['inline'])\n\n  if (jobsConfig.workflows?.length) {\n    jobsConfig.workflows.forEach((workflow) => {\n      workflowSlugs.add(workflow.slug)\n    })\n  }\n\n  if (jobsConfig.tasks?.length) {\n    jobsConfig.tasks.forEach((task) => {\n      if (workflowSlugs.has(task.slug)) {\n        throw new Error(\n          `Task slug \"${task.slug}\" is already used by a workflow. No tasks are allowed to have the same slug as a workflow.`,\n        )\n      }\n      taskSlugs.add(task.slug)\n    })\n  }\n\n  const logFields: Field[] = [\n    {\n      name: 'executedAt',\n      type: 'date',\n      required: true,\n    },\n    {\n      name: 'completedAt',\n      type: 'date',\n      required: true,\n    },\n    {\n      name: 'taskSlug',\n      type: 'select',\n      options: [...taskSlugs],\n      required: true,\n    },\n    {\n      name: 'taskID',\n      type: 'text',\n      required: true,\n    },\n    /**\n     * @todo make required in 4.0\n     */\n    {\n      name: 'input',\n      type: 'json',\n    },\n    {\n      name: 'output',\n      type: 'json',\n    },\n    {\n      name: 'state',\n      type: 'radio',\n      options: ['failed', 'succeeded'],\n      required: true,\n    },\n    {\n      name: 'error',\n      type: 'json',\n      admin: {\n        condition: (_, data) => data.state === 'failed',\n      },\n      required: true,\n    },\n  ]\n\n  if (jobsConfig.addParentToTaskLog) {\n    logFields.push({\n      name: 'parent',\n      type: 'group',\n      fields: [\n        {\n          name: 'taskSlug',\n          type: 'select',\n          options: [...taskSlugs],\n        },\n        {\n          name: 'taskID',\n          type: 'text',\n        },\n      ],\n    })\n  }\n\n  const jobsCollection: CollectionConfig = {\n    slug: jobsCollectionSlug,\n    admin: {\n      group: 'System',\n      hidden: true,\n    },\n    endpoints: [runJobsEndpoint, handleSchedulesJobsEndpoint],\n    fields: [\n      {\n        name: 'input',\n        type: 'json',\n        admin: {\n          description: 'Input data provided to the job',\n        },\n      },\n      {\n        name: 'taskStatus',\n        type: 'json',\n        virtual: true,\n      },\n      {\n        type: 'tabs',\n        tabs: [\n          {\n            fields: [\n              {\n                name: 'completedAt',\n                type: 'date',\n                index: true,\n              },\n              {\n                name: 'totalTried',\n                type: 'number',\n                defaultValue: 0,\n                index: true,\n              },\n              {\n                name: 'hasError',\n                type: 'checkbox',\n                admin: {\n                  description: 'If hasError is true this job will not be retried',\n                },\n                defaultValue: false,\n                index: true,\n              },\n              {\n                name: 'error',\n                type: 'json',\n                admin: {\n                  condition: (data) => data.hasError,\n                  description: 'If hasError is true, this is the error that caused it',\n                },\n              },\n              {\n                name: 'log',\n                type: 'array',\n                admin: {\n                  description: 'Task execution log',\n                },\n                fields: logFields,\n              },\n            ],\n            label: 'Status',\n          },\n        ],\n      },\n      // only include the workflowSlugs field if workflows exist\n      ...((workflowSlugs.size > 0\n        ? [\n            {\n              name: 'workflowSlug',\n              type: 'select',\n              admin: {\n                position: 'sidebar',\n              },\n              index: true,\n              options: [...workflowSlugs],\n            },\n          ]\n        : []) as Field[]),\n      {\n        name: 'taskSlug',\n        type: 'select',\n        admin: {\n          position: 'sidebar',\n        },\n        index: true,\n        options: [...taskSlugs],\n        required: false,\n      },\n      {\n        name: 'queue',\n        type: 'text',\n        admin: {\n          position: 'sidebar',\n        },\n        defaultValue: 'default',\n        index: true,\n      },\n      {\n        name: 'waitUntil',\n        type: 'date',\n        admin: {\n          date: { pickerAppearance: 'dayAndTime' },\n        },\n        index: true,\n      },\n      {\n        name: 'processing',\n        type: 'checkbox',\n        admin: {\n          position: 'sidebar',\n        },\n        defaultValue: false,\n        index: true,\n      },\n    ],\n    hooks: {\n      afterRead: [\n        ({ doc, req }) => {\n          // This hook is used to add the virtual `tasks` field to the document, that is computed from the `log` field\n\n          return jobAfterRead({ config: req.payload.config, doc })\n        },\n      ],\n      /**\n       * If another update comes in after a job as already been cancelled, we need to make sure that update doesn't\n       * change the state of the job.\n       */\n      beforeChange: [\n        ({ data, originalDoc }) => {\n          if (originalDoc?.error?.cancelled) {\n            data.processing = false\n            data.hasError = true\n            delete data.completedAt\n            delete data.waitUntil\n          }\n          return data\n        },\n      ],\n    },\n    lockDocuments: false,\n  }\n\n  if (jobsConfig.stats) {\n    // TODO: In 4.0, this should be added by default.\n    // The meta field can be used to store arbitrary data about the job. The scheduling system uses this to store\n    // `scheduled: true` to indicate that the job was queued by the scheduling system.\n    jobsCollection.fields.push({\n      name: 'meta',\n      type: 'json',\n    })\n  }\n  return jobsCollection\n}\n\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nexport function jobAfterRead({ config, doc }: { config: SanitizedConfig; doc: Job }): Job {\n  doc.taskStatus = getJobTaskStatus({\n    jobLog: doc.log || [],\n  })\n  doc.input = doc.input || {}\n  doc.taskStatus = doc.taskStatus || {}\n  return doc\n}\n"],"names":["handleSchedulesJobsEndpoint","runJobsEndpoint","getJobTaskStatus","jobsCollectionSlug","getDefaultJobsCollection","jobsConfig","workflowSlugs","Set","taskSlugs","workflows","length","forEach","workflow","add","slug","tasks","task","has","Error","logFields","name","type","required","options","admin","condition","_","data","state","addParentToTaskLog","push","fields","jobsCollection","group","hidden","endpoints","description","virtual","tabs","index","defaultValue","hasError","label","size","position","date","pickerAppearance","hooks","afterRead","doc","req","jobAfterRead","config","payload","beforeChange","originalDoc","error","cancelled","processing","completedAt","waitUntil","lockDocuments","stats","taskStatus","jobLog","log","input"],"mappings":";;;;;;;;AAKA,SAASA,2BAA2B,QAAQ,kCAAiC;AAC7E,SAASC,eAAe,QAAQ,sBAAqB;AACrD,SAASC,gBAAgB,QAAQ,mCAAkC;;;;AAE5D,MAAMC,qBAAqB,eAAc;AAEzC,MAAMC,2BAAsF,CACjGC;IAEA,MAAMC,gBAA6B,IAAIC;IACvC,MAAMC,YAAyB,IAAID,IAAI;QAAC;KAAS;IAEjD,IAAIF,WAAWI,SAAS,EAAEC,QAAQ;QAChCL,WAAWI,SAAS,CAACE,OAAO,CAAC,CAACC;YAC5BN,cAAcO,GAAG,CAACD,SAASE,IAAI;QACjC;IACF;IAEA,IAAIT,WAAWU,KAAK,EAAEL,QAAQ;QAC5BL,WAAWU,KAAK,CAACJ,OAAO,CAAC,CAACK;YACxB,IAAIV,cAAcW,GAAG,CAACD,KAAKF,IAAI,GAAG;gBAChC,MAAM,IAAII,MACR,CAAC,WAAW,EAAEF,KAAKF,IAAI,CAAC,0FAA0F,CAAC;YAEvH;YACAN,UAAUK,GAAG,CAACG,KAAKF,IAAI;QACzB;IACF;IAEA,MAAMK,YAAqB;QACzB;YACEC,MAAM;YACNC,MAAM;YACNC,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNC,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNE,SAAS;mBAAIf;aAAU;YACvBc,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNC,UAAU;QACZ;QACA;;KAEC,GACD;YACEF,MAAM;YACNC,MAAM;QACR;QACA;YACED,MAAM;YACNC,MAAM;QACR;QACA;YACED,MAAM;YACNC,MAAM;YACNE,SAAS;gBAAC;gBAAU;aAAY;YAChCD,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNG,OAAO;gBACLC,WAAW,CAACC,GAAGC,OAASA,KAAKC,KAAK,KAAK;YACzC;YACAN,UAAU;QACZ;KACD;IAED,IAAIjB,WAAWwB,kBAAkB,EAAE;QACjCV,UAAUW,IAAI,CAAC;YACbV,MAAM;YACNC,MAAM;YACNU,QAAQ;gBACN;oBACEX,MAAM;oBACNC,MAAM;oBACNE,SAAS;2BAAIf;qBAAU;gBACzB;gBACA;oBACEY,MAAM;oBACNC,MAAM;gBACR;aACD;QACH;IACF;IAEA,MAAMW,iBAAmC;QACvClB,MAAMX;QACNqB,OAAO;YACLS,OAAO;YACPC,QAAQ;QACV;QACAC,WAAW;YAAClC,0RAAAA;YAAiBD,kTAAAA;SAA4B;QACzD+B,QAAQ;YACN;gBACEX,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLY,aAAa;gBACf;YACF;YACA;gBACEhB,MAAM;gBACNC,MAAM;gBACNgB,SAAS;YACX;YACA;gBACEhB,MAAM;gBACNiB,MAAM;oBACJ;wBACEP,QAAQ;4BACN;gCACEX,MAAM;gCACNC,MAAM;gCACNkB,OAAO;4BACT;4BACA;gCACEnB,MAAM;gCACNC,MAAM;gCACNmB,cAAc;gCACdD,OAAO;4BACT;4BACA;gCACEnB,MAAM;gCACNC,MAAM;gCACNG,OAAO;oCACLY,aAAa;gCACf;gCACAI,cAAc;gCACdD,OAAO;4BACT;4BACA;gCACEnB,MAAM;gCACNC,MAAM;gCACNG,OAAO;oCACLC,WAAW,CAACE,OAASA,KAAKc,QAAQ;oCAClCL,aAAa;gCACf;4BACF;4BACA;gCACEhB,MAAM;gCACNC,MAAM;gCACNG,OAAO;oCACLY,aAAa;gCACf;gCACAL,QAAQZ;4BACV;yBACD;wBACDuB,OAAO;oBACT;iBACD;YACH;YACA,0DAA0D;eACrDpC,cAAcqC,IAAI,GAAG,IACtB;gBACE;oBACEvB,MAAM;oBACNC,MAAM;oBACNG,OAAO;wBACLoB,UAAU;oBACZ;oBACAL,OAAO;oBACPhB,SAAS;2BAAIjB;qBAAc;gBAC7B;aACD,GACD,EAAE;YACN;gBACEc,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLoB,UAAU;gBACZ;gBACAL,OAAO;gBACPhB,SAAS;uBAAIf;iBAAU;gBACvBc,UAAU;YACZ;YACA;gBACEF,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLoB,UAAU;gBACZ;gBACAJ,cAAc;gBACdD,OAAO;YACT;YACA;gBACEnB,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLqB,MAAM;wBAAEC,kBAAkB;oBAAa;gBACzC;gBACAP,OAAO;YACT;YACA;gBACEnB,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLoB,UAAU;gBACZ;gBACAJ,cAAc;gBACdD,OAAO;YACT;SACD;QACDQ,OAAO;YACLC,WAAW;gBACT,CAAC,EAAEC,GAAG,EAAEC,GAAG,EAAE;oBACX,4GAA4G;oBAE5G,OAAOC,aAAa;wBAAEC,QAAQF,IAAIG,OAAO,CAACD,MAAM;wBAAEH;oBAAI;gBACxD;aACD;YACD;;;OAGC,GACDK,cAAc;gBACZ,CAAC,EAAE3B,IAAI,EAAE4B,WAAW,EAAE;oBACpB,IAAIA,aAAaC,OAAOC,WAAW;wBACjC9B,KAAK+B,UAAU,GAAG;wBAClB/B,KAAKc,QAAQ,GAAG;wBAChB,OAAOd,KAAKgC,WAAW;wBACvB,OAAOhC,KAAKiC,SAAS;oBACvB;oBACA,OAAOjC;gBACT;aACD;QACH;QACAkC,eAAe;IACjB;IAEA,IAAIxD,WAAWyD,KAAK,EAAE;QACpB,iDAAiD;QACjD,6GAA6G;QAC7G,kFAAkF;QAClF9B,eAAeD,MAAM,CAACD,IAAI,CAAC;YACzBV,MAAM;YACNC,MAAM;QACR;IACF;IACA,OAAOW;AACT,EAAC;AAGM,SAASmB,aAAa,EAAEC,MAAM,EAAEH,GAAG,EAAyC;IACjFA,IAAIc,UAAU,OAAG7D,wSAAAA,EAAiB;QAChC8D,QAAQf,IAAIgB,GAAG,IAAI,EAAE;IACvB;IACAhB,IAAIiB,KAAK,GAAGjB,IAAIiB,KAAK,IAAI,CAAC;IAC1BjB,IAAIc,UAAU,GAAGd,IAAIc,UAAU,IAAI,CAAC;IACpC,OAAOd;AACT"}},
    {"offset": {"line": 2172, "column": 0}, "map": {"version":3,"sources":["file:///Users/stefaniedoll/websites/prepublic/epaper-backend/node_modules/.pnpm/payload%403.64.0_graphql%4016.12.0_typescript%405.5.2/node_modules/payload/src/queues/localAPI.ts"],"sourcesContent":["import type { BaseJob, RunningJobFromTask } from './config/types/workflowTypes.js'\n\nimport {\n  createLocalReq,\n  Forbidden,\n  type Job,\n  type Payload,\n  type PayloadRequest,\n  type Sort,\n  type TypedJobs,\n  type Where,\n} from '../index.js'\nimport { jobAfterRead, jobsCollectionSlug } from './config/collection.js'\nimport { handleSchedules, type HandleSchedulesResult } from './operations/handleSchedules/index.js'\nimport { runJobs } from './operations/runJobs/index.js'\nimport { updateJob, updateJobs } from './utilities/updateJob.js'\n\nexport type RunJobsSilent =\n  | {\n      error?: boolean\n      info?: boolean\n    }\n  | boolean\nexport const getJobsLocalAPI = (payload: Payload) => ({\n  handleSchedules: async (args?: {\n    /**\n     * If you want to schedule jobs from all queues, set this to true.\n     * If you set this to true, the `queue` property will be ignored.\n     *\n     * @default false\n     */\n    allQueues?: boolean\n    // By default, schedule all queues - only scheduling jobs scheduled to be added to the `default` queue would not make sense\n    // here, as you'd usually specify a different queue than `default` here, especially if this is used in combination with autorun.\n    // The `queue` property for setting up schedules is required, and not optional.\n    /**\n     * If you want to only schedule jobs that are set to schedule in a specific queue, set this to the queue name.\n     *\n     * @default jobs from the `default` queue will be executed.\n     */\n    queue?: string\n    req?: PayloadRequest\n  }): Promise<HandleSchedulesResult> => {\n    const newReq: PayloadRequest = args?.req ?? (await createLocalReq({}, payload))\n\n    return await handleSchedules({\n      allQueues: args?.allQueues,\n      queue: args?.queue,\n      req: newReq,\n    })\n  },\n  queue: async <\n    // eslint-disable-next-line @typescript-eslint/no-duplicate-type-constituents\n    TTaskOrWorkflowSlug extends keyof TypedJobs['tasks'] | keyof TypedJobs['workflows'],\n  >(\n    args:\n      | {\n          input: TypedJobs['tasks'][TTaskOrWorkflowSlug]['input']\n          meta?: BaseJob['meta']\n          /**\n           * If set to false, access control as defined in jobsConfig.access.queue will be run.\n           * By default, this is true and no access control will be run.\n           * If you set this to false and do not have jobsConfig.access.queue defined, the default access control will be\n           * run (which is a function that returns `true` if the user is logged in).\n           *\n           * @default true\n           */\n          overrideAccess?: boolean\n          queue?: string\n          req?: PayloadRequest\n          task: TTaskOrWorkflowSlug extends keyof TypedJobs['tasks'] ? TTaskOrWorkflowSlug : never\n          waitUntil?: Date\n          workflow?: never\n        }\n      | {\n          input: TypedJobs['workflows'][TTaskOrWorkflowSlug]['input']\n          meta?: BaseJob['meta']\n          /**\n           * If set to false, access control as defined in jobsConfig.access.queue will be run.\n           * By default, this is true and no access control will be run.\n           * If you set this to false and do not have jobsConfig.access.queue defined, the default access control will be\n           * run (which is a function that returns `true` if the user is logged in).\n           *\n           * @default true\n           */\n          overrideAccess?: boolean\n          queue?: string\n          req?: PayloadRequest\n          task?: never\n          waitUntil?: Date\n          workflow: TTaskOrWorkflowSlug extends keyof TypedJobs['workflows']\n            ? TTaskOrWorkflowSlug\n            : never\n        },\n  ): Promise<\n    TTaskOrWorkflowSlug extends keyof TypedJobs['workflows']\n      ? Job<TTaskOrWorkflowSlug>\n      : RunningJobFromTask<TTaskOrWorkflowSlug>\n  > => {\n    const overrideAccess = args?.overrideAccess !== false\n    const req: PayloadRequest = args.req ?? (await createLocalReq({}, payload))\n\n    if (!overrideAccess) {\n      /**\n       * By default, jobsConfig.access.queue will be `defaultAccess` which is a function that returns `true` if the user is logged in.\n       */\n      const accessFn = payload.config.jobs?.access?.queue ?? (() => true)\n      const hasAccess = await accessFn({ req })\n      if (!hasAccess) {\n        throw new Forbidden(req.t)\n      }\n    }\n\n    let queue: string | undefined = undefined\n\n    // If user specifies queue, use that\n    if (args.queue) {\n      queue = args.queue\n    } else if (args.workflow) {\n      // Otherwise, if there is a workflow specified, and it has a default queue to use,\n      // use that\n      const workflow = payload.config.jobs?.workflows?.find(({ slug }) => slug === args.workflow)\n      if (workflow?.queue) {\n        queue = workflow.queue\n      }\n    }\n\n    const data: Partial<Job> = {\n      input: args.input,\n    }\n\n    if (queue) {\n      data.queue = queue\n    }\n    if (args.waitUntil) {\n      data.waitUntil = args.waitUntil?.toISOString()\n    }\n    if (args.workflow) {\n      data.workflowSlug = args.workflow as string\n    }\n    if (args.task) {\n      data.taskSlug = args.task as string\n    }\n\n    if (args.meta) {\n      data.meta = args.meta\n    }\n\n    type ReturnType = TTaskOrWorkflowSlug extends keyof TypedJobs['workflows']\n      ? Job<TTaskOrWorkflowSlug>\n      : RunningJobFromTask<TTaskOrWorkflowSlug> // Type assertion is still needed here\n\n    if (payload?.config?.jobs?.depth || payload?.config?.jobs?.runHooks) {\n      return (await payload.create({\n        collection: jobsCollectionSlug,\n        data,\n        depth: payload.config.jobs.depth ?? 0,\n        overrideAccess,\n        req,\n      })) as ReturnType\n    } else {\n      return jobAfterRead({\n        config: payload.config,\n        doc: await payload.db.create({\n          collection: jobsCollectionSlug,\n          data,\n          req,\n        }),\n      }) as unknown as ReturnType\n    }\n  },\n\n  run: async (args?: {\n    /**\n     * If you want to run jobs from all queues, set this to true.\n     * If you set this to true, the `queue` property will be ignored.\n     *\n     * @default false\n     */\n    allQueues?: boolean\n    /**\n     * The maximum number of jobs to run in this invocation\n     *\n     * @default 10\n     */\n    limit?: number\n    /**\n     * If set to false, access control as defined in jobsConfig.access.run will be run.\n     * By default, this is true and no access control will be run.\n     * If you set this to false and do not have jobsConfig.access.run defined, the default access control will be\n     * run (which is a function that returns `true` if the user is logged in).\n     *\n     * @default true\n     */\n    overrideAccess?: boolean\n    /**\n     * Adjust the job processing order using a Payload sort string.\n     *\n     * FIFO would equal `createdAt` and LIFO would equal `-createdAt`.\n     */\n    processingOrder?: Sort\n    /**\n     * If you want to run jobs from a specific queue, set this to the queue name.\n     *\n     * @default jobs from the `default` queue will be executed.\n     */\n    queue?: string\n    req?: PayloadRequest\n    /**\n     * By default, jobs are run in parallel.\n     * If you want to run them in sequence, set this to true.\n     */\n    sequential?: boolean\n    /**\n     * If set to true, the job system will not log any output to the console (for both info and error logs).\n     * Can be an option for more granular control over logging.\n     *\n     * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n     *\n     * @default false\n     */\n    silent?: RunJobsSilent\n    where?: Where\n  }): Promise<ReturnType<typeof runJobs>> => {\n    const newReq: PayloadRequest = args?.req ?? (await createLocalReq({}, payload))\n\n    return await runJobs({\n      allQueues: args?.allQueues,\n      limit: args?.limit,\n      overrideAccess: args?.overrideAccess !== false,\n      processingOrder: args?.processingOrder,\n      queue: args?.queue,\n      req: newReq,\n      sequential: args?.sequential,\n      silent: args?.silent,\n      where: args?.where,\n    })\n  },\n\n  runByID: async (args: {\n    id: number | string\n    /**\n     * If set to false, access control as defined in jobsConfig.access.run will be run.\n     * By default, this is true and no access control will be run.\n     * If you set this to false and do not have jobsConfig.access.run defined, the default access control will be\n     * run (which is a function that returns `true` if the user is logged in).\n     *\n     * @default true\n     */\n    overrideAccess?: boolean\n    req?: PayloadRequest\n    /**\n     * If set to true, the job system will not log any output to the console (for both info and error logs).\n     * Can be an option for more granular control over logging.\n     *\n     * This will not automatically affect user-configured logs (e.g. if you call `console.log` or `payload.logger.info` in your job code).\n     *\n     * @default false\n     */\n    silent?: RunJobsSilent\n  }): Promise<ReturnType<typeof runJobs>> => {\n    const newReq: PayloadRequest = args.req ?? (await createLocalReq({}, payload))\n\n    return await runJobs({\n      id: args.id,\n      overrideAccess: args.overrideAccess !== false,\n      req: newReq,\n      silent: args.silent,\n    })\n  },\n\n  cancel: async (args: {\n    /**\n     * If set to false, access control as defined in jobsConfig.access.cancel will be run.\n     * By default, this is true and no access control will be run.\n     * If you set this to false and do not have jobsConfig.access.cancel defined, the default access control will be\n     * run (which is a function that returns `true` if the user is logged in).\n     *\n     * @default true\n     */\n    overrideAccess?: boolean\n    queue?: string\n    req?: PayloadRequest\n    where: Where\n  }): Promise<void> => {\n    const req: PayloadRequest = args.req ?? (await createLocalReq({}, payload))\n\n    const overrideAccess = args.overrideAccess !== false\n    if (!overrideAccess) {\n      /**\n       * By default, jobsConfig.access.cancel will be `defaultAccess` which is a function that returns `true` if the user is logged in.\n       */\n      const accessFn = payload.config.jobs?.access?.cancel ?? (() => true)\n      const hasAccess = await accessFn({ req })\n      if (!hasAccess) {\n        throw new Forbidden(req.t)\n      }\n    }\n\n    const and: Where[] = [\n      args.where,\n      {\n        completedAt: {\n          exists: false,\n        },\n      },\n      {\n        hasError: {\n          not_equals: true,\n        },\n      },\n    ]\n\n    if (args.queue) {\n      and.push({\n        queue: {\n          equals: args.queue,\n        },\n      })\n    }\n\n    await updateJobs({\n      data: {\n        completedAt: null,\n        error: {\n          cancelled: true,\n        },\n        hasError: true,\n        processing: false,\n        waitUntil: null,\n      },\n      depth: 0, // No depth, since we're not returning\n      disableTransaction: true,\n      req,\n      returning: false,\n      where: { and },\n    })\n  },\n\n  cancelByID: async (args: {\n    id: number | string\n    /**\n     * If set to false, access control as defined in jobsConfig.access.cancel will be run.\n     * By default, this is true and no access control will be run.\n     * If you set this to false and do not have jobsConfig.access.cancel defined, the default access control will be\n     * run (which is a function that returns `true` if the user is logged in).\n     *\n     * @default true\n     */\n    overrideAccess?: boolean\n    req?: PayloadRequest\n  }): Promise<void> => {\n    const req: PayloadRequest = args.req ?? (await createLocalReq({}, payload))\n\n    const overrideAccess = args.overrideAccess !== false\n    if (!overrideAccess) {\n      /**\n       * By default, jobsConfig.access.cancel will be `defaultAccess` which is a function that returns `true` if the user is logged in.\n       */\n      const accessFn = payload.config.jobs?.access?.cancel ?? (() => true)\n      const hasAccess = await accessFn({ req })\n      if (!hasAccess) {\n        throw new Forbidden(req.t)\n      }\n    }\n\n    await updateJob({\n      id: args.id,\n      data: {\n        completedAt: null,\n        error: {\n          cancelled: true,\n        },\n        hasError: true,\n        processing: false,\n        waitUntil: null,\n      },\n      depth: 0, // No depth, since we're not returning\n      disableTransaction: true,\n      req,\n      returning: false,\n    })\n  },\n})\n"],"names":["createLocalReq","Forbidden","jobAfterRead","jobsCollectionSlug","handleSchedules","runJobs","updateJob","updateJobs","getJobsLocalAPI","payload","args","newReq","req","allQueues","queue","overrideAccess","accessFn","config","jobs","access","hasAccess","t","undefined","workflow","workflows","find","slug","data","input","waitUntil","toISOString","workflowSlug","task","taskSlug","meta","depth","runHooks","create","collection","doc","db","run","limit","processingOrder","sequential","silent","where","runByID","id","cancel","and","completedAt","exists","hasError","not_equals","push","equals","error","cancelled","processing","disableTransaction","returning","cancelByID"],"mappings":";;;;;AAEA,SACEA,cAAc,EACdC,SAAS,QAOJ,cAAa;AACpB,SAASC,YAAY,EAAEC,kBAAkB,QAAQ,yBAAwB;AACzE,SAASC,eAAe,QAAoC,wCAAuC;AACnG,SAASC,OAAO,QAAQ,gCAA+B;AACvD,SAASC,SAAS,EAAEC,UAAU,QAAQ,2BAA0B;;;;;;AAQzD,MAAMC,kBAAkB,CAACC,UAAsB,CAAA;QACpDL,iBAAiB,OAAOM;YAmBtB,MAAMC,SAAyBD,MAAME,OAAQ,UAAMZ,0RAAAA,EAAe,CAAC,GAAGS;YAEtE,OAAO,UAAML,gTAAAA,EAAgB;gBAC3BS,WAAWH,MAAMG;gBACjBC,OAAOJ,MAAMI;gBACbF,KAAKD;YACP;QACF;QACAG,OAAO,OAILJ;YA4CA,MAAMK,iBAAiBL,MAAMK,mBAAmB;YAChD,MAAMH,MAAsBF,KAAKE,GAAG,IAAK,UAAMZ,0RAAAA,EAAe,CAAC,GAAGS;YAElE,IAAI,CAACM,gBAAgB;gBACnB;;OAEC,GACD,MAAMC,WAAWP,QAAQQ,MAAM,CAACC,IAAI,EAAEC,QAAQL,SAAU,CAAA,IAAM,IAAG;gBACjE,MAAMM,YAAY,MAAMJ,SAAS;oBAAEJ;gBAAI;gBACvC,IAAI,CAACQ,WAAW;oBACd,MAAM,IAAInB,6QAAAA,CAAUW,IAAIS,CAAC;gBAC3B;YACF;YAEA,IAAIP,QAA4BQ;YAEhC,oCAAoC;YACpC,IAAIZ,KAAKI,KAAK,EAAE;gBACdA,QAAQJ,KAAKI,KAAK;YACpB,OAAO,IAAIJ,KAAKa,QAAQ,EAAE;gBACxB,kFAAkF;gBAClF,WAAW;gBACX,MAAMA,WAAWd,QAAQQ,MAAM,CAACC,IAAI,EAAEM,WAAWC,KAAK,CAAC,EAAEC,IAAI,EAAE,GAAKA,SAAShB,KAAKa,QAAQ;gBAC1F,IAAIA,UAAUT,OAAO;oBACnBA,QAAQS,SAAST,KAAK;gBACxB;YACF;YAEA,MAAMa,OAAqB;gBACzBC,OAAOlB,KAAKkB,KAAK;YACnB;YAEA,IAAId,OAAO;gBACTa,KAAKb,KAAK,GAAGA;YACf;YACA,IAAIJ,KAAKmB,SAAS,EAAE;gBAClBF,KAAKE,SAAS,GAAGnB,KAAKmB,SAAS,EAAEC;YACnC;YACA,IAAIpB,KAAKa,QAAQ,EAAE;gBACjBI,KAAKI,YAAY,GAAGrB,KAAKa,QAAQ;YACnC;YACA,IAAIb,KAAKsB,IAAI,EAAE;gBACbL,KAAKM,QAAQ,GAAGvB,KAAKsB,IAAI;YAC3B;YAEA,IAAItB,KAAKwB,IAAI,EAAE;gBACbP,KAAKO,IAAI,GAAGxB,KAAKwB,IAAI;YACvB;YAI4C,sCAAsC;YAElF,IAAIzB,SAASQ,QAAQC,MAAMiB,SAAS1B,SAASQ,QAAQC,MAAMkB,UAAU;gBACnE,OAAQ,MAAM3B,QAAQ4B,MAAM,CAAC;oBAC3BC,YAAYnC,iSAAAA;oBACZwB;oBACAQ,OAAO1B,QAAQQ,MAAM,CAACC,IAAI,CAACiB,KAAK,IAAI;oBACpCpB;oBACAH;gBACF;YACF,OAAO;gBACL,WAAOV,2RAAAA,EAAa;oBAClBe,QAAQR,QAAQQ,MAAM;oBACtBsB,KAAK,MAAM9B,QAAQ+B,EAAE,CAACH,MAAM,CAAC;wBAC3BC,YAAYnC,iSAAAA;wBACZwB;wBACAf;oBACF;gBACF;YACF;QACF;QAEA6B,KAAK,OAAO/B;YAoDV,MAAMC,SAAyBD,MAAME,OAAQ,UAAMZ,0RAAAA,EAAe,CAAC,GAAGS;YAEtE,OAAO,UAAMJ,gSAAAA,EAAQ;gBACnBQ,WAAWH,MAAMG;gBACjB6B,OAAOhC,MAAMgC;gBACb3B,gBAAgBL,MAAMK,mBAAmB;gBACzC4B,iBAAiBjC,MAAMiC;gBACvB7B,OAAOJ,MAAMI;gBACbF,KAAKD;gBACLiC,YAAYlC,MAAMkC;gBAClBC,QAAQnC,MAAMmC;gBACdC,OAAOpC,MAAMoC;YACf;QACF;QAEAC,SAAS,OAAOrC;YAsBd,MAAMC,SAAyBD,KAAKE,GAAG,IAAK,UAAMZ,0RAAAA,EAAe,CAAC,GAAGS;YAErE,OAAO,UAAMJ,gSAAAA,EAAQ;gBACnB2C,IAAItC,KAAKsC,EAAE;gBACXjC,gBAAgBL,KAAKK,cAAc,KAAK;gBACxCH,KAAKD;gBACLkC,QAAQnC,KAAKmC,MAAM;YACrB;QACF;QAEAI,QAAQ,OAAOvC;YAcb,MAAME,MAAsBF,KAAKE,GAAG,IAAK,UAAMZ,0RAAAA,EAAe,CAAC,GAAGS;YAElE,MAAMM,iBAAiBL,KAAKK,cAAc,KAAK;YAC/C,IAAI,CAACA,gBAAgB;gBACnB;;OAEC,GACD,MAAMC,WAAWP,QAAQQ,MAAM,CAACC,IAAI,EAAEC,QAAQ8B,UAAW,CAAA,IAAM,IAAG;gBAClE,MAAM7B,YAAY,MAAMJ,SAAS;oBAAEJ;gBAAI;gBACvC,IAAI,CAACQ,WAAW;oBACd,MAAM,IAAInB,6QAAAA,CAAUW,IAAIS,CAAC;gBAC3B;YACF;YAEA,MAAM6B,MAAe;gBACnBxC,KAAKoC,KAAK;gBACV;oBACEK,aAAa;wBACXC,QAAQ;oBACV;gBACF;gBACA;oBACEC,UAAU;wBACRC,YAAY;oBACd;gBACF;aACD;YAED,IAAI5C,KAAKI,KAAK,EAAE;gBACdoC,IAAIK,IAAI,CAAC;oBACPzC,OAAO;wBACL0C,QAAQ9C,KAAKI,KAAK;oBACpB;gBACF;YACF;YAEA,UAAMP,2RAAAA,EAAW;gBACfoB,MAAM;oBACJwB,aAAa;oBACbM,OAAO;wBACLC,WAAW;oBACb;oBACAL,UAAU;oBACVM,YAAY;oBACZ9B,WAAW;gBACb;gBACAM,OAAO;gBACPyB,oBAAoB;gBACpBhD;gBACAiD,WAAW;gBACXf,OAAO;oBAAEI;gBAAI;YACf;QACF;QAEAY,YAAY,OAAOpD;YAajB,MAAME,MAAsBF,KAAKE,GAAG,IAAK,UAAMZ,0RAAAA,EAAe,CAAC,GAAGS;YAElE,MAAMM,iBAAiBL,KAAKK,cAAc,KAAK;YAC/C,IAAI,CAACA,gBAAgB;gBACnB;;OAEC,GACD,MAAMC,WAAWP,QAAQQ,MAAM,CAACC,IAAI,EAAEC,QAAQ8B,UAAW,CAAA,IAAM,IAAG;gBAClE,MAAM7B,YAAY,MAAMJ,SAAS;oBAAEJ;gBAAI;gBACvC,IAAI,CAACQ,WAAW;oBACd,MAAM,IAAInB,6QAAAA,CAAUW,IAAIS,CAAC;gBAC3B;YACF;YAEA,UAAMf,0RAAAA,EAAU;gBACd0C,IAAItC,KAAKsC,EAAE;gBACXrB,MAAM;oBACJwB,aAAa;oBACbM,OAAO;wBACLC,WAAW;oBACb;oBACAL,UAAU;oBACVM,YAAY;oBACZ9B,WAAW;gBACb;gBACAM,OAAO;gBACPyB,oBAAoB;gBACpBhD;gBACAiD,WAAW;YACb;QACF;IACF,CAAA,EAAE"}}]
}